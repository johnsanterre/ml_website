{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 15: Future Trends in AI - Homework\n",
        "\n",
        "**ML2: Advanced Machine Learning**\n",
        "\n",
        "**Estimated Time**: 1 hour\n",
        "\n",
        "---\n",
        "\n",
        "This homework combines programming exercises and knowledge-based questions to reinforce this week's concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Run this cell to import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Programming Exercises (60%)\n",
        "\n",
        "Complete the following programming tasks. Read each description carefully and implement the requested functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Experiment: Multimodal Capabilities\n",
        "\n",
        "**Time**: 10 min\n",
        "\n",
        "Explore how models can process text AND images together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multimodal models (GPT-4V, Gemini) can understand images + text\n",
        "\n",
        "# Task 1: Image captioning\n",
        "# Input: [image of a cat]\n",
        "# Output: \"A gray cat sitting on a windowsill\"\n",
        "\n",
        "# Task 2: Visual question answering\n",
        "# Input: [image of a chart] + \"What's the trend in 2023?\"\n",
        "# Output: \"The trend shows an upward trajectory in 2023\"\n",
        "\n",
        "# Task 3: OCR + reasoning\n",
        "# Input: [image of a receipt] + \"How much did I spend on groceries?\"\n",
        "# Output: \"$45.67\"\n",
        "\n",
        "# TODO: Consider what new applications multimodality enables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Knowledge Questions (40%)\n",
        "\n",
        "Answer the following questions to test your conceptual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 (Short Answer)\n",
        "\n",
        "**Question 1 - Multimodality**\n\nText-only LLMs:\n- Input: text → Output: text\n\nMultimodal LLMs:\n- Input: text + images + audio → Output: text (or images)\n\nExplain:\n1. What new capabilities does multimodality unlock?\n2. What challenges arise from combining modalities?\n3. Give 3 real-world applications.\n",
        "\n",
        "**Hint**: New: visual reasoning, accessibility, richer understanding. Challenges: alignment, training complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2 (Short Answer)\n",
        "\n",
        "**Question 2 - Efficiency Frontiers**\n\nTrends in making LLMs more efficient:\n- LoRA: Fine-tune only a small subset of parameters\n- Quantization: Use fewer bits per parameter (FP16 → INT8)\n- Distillation: Train smaller model to mimic larger model\n- Mixture of Experts: Activate only relevant parts of model\n\nExplain: Why is efficiency becoming critical as models grow?\n",
        "\n",
        "**Hint**: Cost, energy, environmental impact, accessibility. Can't keep scaling infinitely."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3 (Multiple Choice)\n",
        "\n",
        "**Question 3 - LoRA (Low-Rank Adaptation)**\n\nInstead of fine-tuning 175B parameters, LoRA fine-tunes ~1M parameters.\n\nHow does this work?\n\nA) It removes most of the model\nB) It trains small adapter layers while freezing the base model\nC) It only works on small models\nD) It eliminates the need for training data\n",
        "\n",
        "A) It removes most of the model\n",
        "B) It trains small adapter layers while freezing the base model\n",
        "C) It only works on small models\n",
        "D) It eliminates the need for training data\n",
        "\n",
        "**Hint**: LoRA adds small trainable matrices that adapt the frozen base model efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 4 (Short Answer)\n",
        "\n",
        "**Question 4 - Open Source vs Closed Source**\n\nClosed: GPT-4 (OpenAI), Claude (Anthropic)\nOpen: Llama, Mistral, Falcon\n\nExplain:\n1. What advantages does open source provide?\n2. What are the risks of fully open models?\n3. What's the trend in the community?\n",
        "\n",
        "**Hint**: Open = transparency, customization, research. Risks = misuse, safety. Trend = moving toward open."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5 (Short Answer)\n",
        "\n",
        "**Question 5 - Mixture of Experts (MoE)**\n\nInstead of activating the ENTIRE model, MoE activates only relevant \"experts\" for each input.\n\nExample: For a coding question, activate coding expert. For medical, activate medical expert.\n\nExplain:\n1. What efficiency gains does this provide?\n2. How does the model decide which experts to activate?\n3. What's the tradeoff?\n",
        "\n",
        "**Hint**: Efficiency: less computation per input. Router network selects experts. Tradeoff: complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 6 (Multiple Choice)\n",
        "\n",
        "**Question 6 - Context Window Scaling**\n\nGPT-3: 4k tokens\nGPT-4: 8k-128k tokens\nClaude: 100k-200k tokens\n\nWhy is longer context important?\n\nA) Makes model bigger\nB) Enables processing entire books, codebases, conversations\nC) Faster inference\nD) Lower cost\n",
        "\n",
        "A) Makes model bigger\n",
        "B) Enables processing entire books, codebases, conversations\n",
        "C) Faster inference\n",
        "D) Lower cost\n",
        "\n",
        "**Hint**: Longer context = can fit more information without external memory/retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 7 (Short Answer)\n",
        "\n",
        "**Question 7 - Synthetic Data**\n\nRunning out of internet text to train on? Use LLMs to GENERATE training data.\n\nPhi-2: Trained largely on synthetic data, performs well despite small size.\n\nExplain:\n1. How can you use GPT-4 to generate training data for smaller models?\n2. What are the risks of synthetic data?\n3. When is this approach valuable?\n",
        "\n",
        "**Hint**: GPT-4 generates diverse examples. Risks: bias amplification, homogenization. Valuable when real data scarce."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 8 (Short Answer)\n",
        "\n",
        "**Question 8 - Constitutional AI**\n\nInstead of RLHF, train LLMs using a \"constitution\" (set of principles).\n\nExample principle: \"Be helpful, harmless, and honest.\"\n\nExplain:\n1. How does this differ from RLHF?\n2. What advantages might it have?\n3. What challenges remain?\n",
        "\n",
        "**Hint**: Constitution = explicit rules vs implicit human feedback. Advantages: transparency, scalability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 9 (Short Answer)\n",
        "\n",
        "**Question 9 - Compute Trends**\n\nGPT-3: ~3.14 × 10²³ FLOPs to train\nGPT-4: (estimated) ~10²⁵ FLOPs\n\nExplain:\n1. Can this exponential growth continue?\n2. What are the bottlenecks (energy, cost, hardware)?\n3. What alternatives to \"bigger is better\" are being explored?\n",
        "\n",
        "**Hint**: Can't scale forever. Bottlenecks: power, chips, cost. Alternatives: efficiency, architecture improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 10 (Short Answer)\n",
        "\n",
        "**Question 10 - Your Prediction**\n\nCrystal ball time! What do you predict for LLMs in the next 5 years?\n\nConsider:\n- Model capabilities\n- Accessibility (open source, cost)\n- Multimodality\n- Applications\n- Societal impact\n\nExplain your reasoning.\n",
        "\n",
        "**Hint**: No wrong answer! Think about current trends and extrapolate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Submission\n",
        "\n",
        "Before submitting:\n",
        "1. Run all cells to ensure code executes without errors\n",
        "2. Check that all questions are answered\n",
        "3. Review your explanations for clarity\n",
        "\n",
        "**To Submit**:\n",
        "- File → Download → Download .ipynb\n",
        "- Submit the notebook file to your course LMS\n",
        "\n",
        "**Note**: Make sure your name is in the filename (e.g., homework_01_yourname.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}