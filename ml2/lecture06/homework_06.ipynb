{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 6: From Autoencoders to Embeddings - Homework\\n",
        "\\n",
        "**ML2: Advanced Machine Learning**\\n",
        "\\n",
        "**Estimated Time**: 1 hour\\n",
        "\\n",
        "---\\n",
        "\\n",
        "This homework combines programming exercises and knowledge-based questions to reinforce this week's concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\\n",
        "\\n",
        "Run this cell to import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\\n",
        "import matplotlib.pyplot as plt\\n",
        "import torch\\n",
        "import torch.nn as nn\\n",
        "\\n",
        "# Set random seed for reproducibility\\n",
        "np.random.seed(42)\\n",
        "torch.manual_seed(42)\\n",
        "\\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\\n",
        "## Part 1: Programming Exercises (60%)\\n",
        "\\n",
        "Complete the following programming tasks. Read each description carefully and implement the requested functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Word Embedding Analogies\\n",
        "\\n",
        "**Time**: 15 min\\n",
        "\\n",
        "Use pre-trained word embeddings to solve analogy tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using pre-trained embeddings (e.g., Word2Vec or GloVe)",
        "# TODO: Load embeddings",
        "# TODO: Implement function to solve analogies: king - man + woman = ?",
        "# TODO: Test with various analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Visualize Word Embeddings\\n",
        "\\n",
        "**Time**: 25 min\\n",
        "\\n",
        "Create a 2D visualization of word embedding space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA",
        "import matplotlib.pyplot as plt",
        "",
        "# TODO: Select subset of words",
        "# TODO: Reduce to 2D using PCA or t-SNE",
        "# TODO: Plot and label points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\\n",
        "## Part 2: Knowledge Questions (40%)\\n",
        "\\n",
        "Answer the following questions to test your conceptual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 (Multiple Choice)\\n",
        "\\n",
        "What is the main difference between Word2Vec and GloVe?\\n",
        "\\n",
        "A) Word2Vec is supervised, GloVe is unsupervised\\n",
        "B) Word2Vec captures local context, GloVe uses global co-occurrence statistics\\n",
        "C) GloVe only works for English\\n",
        "D) Word2Vec cannot handle rare words\\n",
        "\\n",
        "**Hint**: Consider the training objectives of each method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\\n",
        "\\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2 (Short Answer)\\n",
        "\\n",
        "Explain how negative sampling helps make Word2Vec training efficient.\\n",
        "\\n",
        "**Hint**: What's the problem with computing softmax over the entire vocabulary?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\\n",
        "\\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\\n",
        "## Submission\\n",
        "\\n",
        "Before submitting:\\n",
        "1. Run all cells to ensure code executes without errors\\n",
        "2. Check that all questions are answered\\n",
        "3. Review your explanations for clarity\\n",
        "\\n",
        "**To Submit**:\\n",
        "- File → Download → Download .ipynb\\n",
        "- Submit the notebook file to your course LMS\\n",
        "\\n",
        "**Note**: Make sure your name is in the filename (e.g., homework_01_yourname.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}