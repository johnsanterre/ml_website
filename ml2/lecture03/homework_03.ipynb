{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 3: Building Real-World Housing Price Predictor - Homework\n",
        "\n",
        "**ML2: Advanced Machine Learning**\n",
        "\n",
        "**Estimated Time**: 1 hour\n",
        "\n",
        "---\n",
        "\n",
        "This homework combines programming exercises and knowledge-based questions to reinforce this week's concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Run this cell to import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Programming Exercises (60%)\n",
        "\n",
        "Complete the following programming tasks. Read each description carefully and implement the requested functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Experiment: Comparing Evaluation Metrics\n",
        "\n",
        "**Time**: 10 min\n",
        "\n",
        "Train a simple regression model and observe how different metrics (MSE, MAE, R²) tell different stories about model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic regression data with some outliers\n",
        "torch.manual_seed(42)\n",
        "X = torch.randn(100, 1) * 10\n",
        "y_true = 2 * X + 5 + torch.randn(100, 1) * 2\n",
        "\n",
        "# Add 5 outliers\n",
        "outlier_idx = torch.randint(0, 100, (5,))\n",
        "y_true[outlier_idx] += torch.randn(5, 1) * 20\n",
        "\n",
        "# Simple model\n",
        "model = nn.Linear(1, 1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(X)\n",
        "    loss = nn.MSELoss()(pred, y_true)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Evaluate with different metrics\n",
        "with torch.no_grad():\n",
        "    final_pred = model(X)\n",
        "    mse = nn.MSELoss()(final_pred, y_true).item()\n",
        "    mae = nn.L1Loss()(final_pred, y_true).item()\n",
        "    \n",
        "    # R-squared\n",
        "    ss_res = torch.sum((y_true - final_pred) ** 2).item()\n",
        "    ss_tot = torch.sum((y_true - y_true.mean()) ** 2).item()\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "    \n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"R²: {r2:.4f}\")\n",
        "\n",
        "# TODO: Answer reflection questions about what each metric tells you"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Experiment: Detecting Overfitting\n",
        "\n",
        "**Time**: 12 min\n",
        "\n",
        "Observe what overfitting looks like by comparing train vs validation performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Generate data\n",
        "torch.manual_seed(42)\n",
        "X_train = torch.randn(50, 1) * 5\n",
        "y_train = 3 * X_train + 2 + torch.randn(50, 1) * 1\n",
        "\n",
        "X_val = torch.randn(20, 1) * 5\n",
        "y_val = 3 * X_val + 2 + torch.randn(20, 1) * 1\n",
        "\n",
        "# Model with too much capacity (overly complex for the task)\n",
        "overfit_model = nn.Sequential(\n",
        "    nn.Linear(1, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 1)\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(overfit_model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(500):\n",
        "    # Train\n",
        "    optimizer.zero_grad()\n",
        "    train_pred = overfit_model(X_train)\n",
        "    train_loss = criterion(train_pred, y_train)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Validate\n",
        "    with torch.no_grad():\n",
        "        val_pred = overfit_model(X_val)\n",
        "        val_loss = criterion(val_pred, y_val)\n",
        "    \n",
        "    train_losses.append(train_loss.item())\n",
        "    val_losses.append(val_loss.item())\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
        "\n",
        "# TODO: Observe the pattern. When does overfitting start?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Knowledge Questions (40%)\n",
        "\n",
        "Answer the following questions to test your conceptual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 (Short Answer)\n",
        "\n",
        "**Question 1 - Understanding MSE vs MAE**\n\nMSE = mean((y_true - y_pred)²)\nMAE = mean(|y_true - y_pred|)\n\nExplain:\n1. Why does MSE use squaring? What effect does this have?\n2. When would you prefer MAE over MSE?\n3. If you have outliers in your data, which metric would be more affected? Why?\n",
        "\n",
        "**Hint**: Think about what happens when you square large errors vs small errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2 (Short Answer)\n",
        "\n",
        "**Question 2 - What R² Really Means**\n\nR² = 1 - (SS_residual / SS_total)\n\nR² ranges from 0 to 1 (or sometimes negative for very bad models).\n\nExplain in plain language:\n1. What does R² = 0.8 mean about your model?\n2. What does R² = 0 mean?\n3. Why is R² more interpretable than MSE for comparing models across different datasets?\n",
        "\n",
        "**Hint**: R² represents the proportion of variance explained by the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3 (Multiple Choice)\n",
        "\n",
        "**Question 3 - Metric Selection**\n\nYou're building a house price predictor. Buyers care most about absolute dollar errors (not squared errors), and there are some mansions that could skew your metrics.\n\nWhich metric should you prioritize?\n\nA) MSE - emphasizes large errors\nB) MAE - treats all errors equally\nC) R² - explains variance\nD) RMSE - root of MSE\n",
        "\n",
        "A) MSE - emphasizes large errors\n",
        "B) MAE - treats all errors equally\n",
        "C) R² - explains variance\n",
        "D) RMSE - root of MSE\n",
        "\n",
        "**Hint**: Which metric is in dollars and doesn't over-penalize mansion outliers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 4 (Short Answer)\n",
        "\n",
        "**Question 4 - Experiment Reflection: Metrics**\n\nAfter running the 'Comparing Evaluation Metrics' experiment:\n\nThe data had 5 outliers added. Compare the MSE vs MAE values you observed.\n\nExplain: Which metric was more affected by the outliers, and why does this happen mathematically?\n",
        "\n",
        "**Hint**: Remember that MSE squares all errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5 (Short Answer)\n",
        "\n",
        "**Question 5 - Detecting Overfitting**\n\nBased on the 'Detecting Overfitting' experiment:\n\nYou should see training loss decrease continuously while validation loss eventually increases.\n\nExplain:\n1. At what point does overfitting start?\n2. What is the model doing when train loss drops but val loss rises?\n3. How would you prevent this in practice?\n",
        "\n",
        "**Hint**: The model starts memorizing training data instead of learning patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 6 (Short Answer)\n",
        "\n",
        "**Question 6 - Train/Val Split Purpose**\n\nExplain the PURPOSE of splitting data into train and validation sets.\n\nWhat specific problem does this solve? What would happen if you only evaluated on training data?\n",
        "\n",
        "**Hint**: You need separate data to detect when the model stops generalizing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 7 (Multiple Choice)\n",
        "\n",
        "**Question 7 - Model Complexity and Overfitting**\n\nYou have 100 training examples. Which model is MORE likely to overfit?\n\nA) Linear model: y = wx + b (2 parameters)\nB) Deep network with 10,000 parameters\nC) Both equally likely\nD) Neither will overfit\n",
        "\n",
        "A) Linear model: y = wx + b (2 parameters)\n",
        "B) Deep network with 10,000 parameters\n",
        "C) Both equally likely\n",
        "D) Neither will overfit\n",
        "\n",
        "**Hint**: More parameters = more capacity to memorize training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 8 (Short Answer)\n",
        "\n",
        "**Question 8 - Systematic Improvement**\n\nYou train a model and get: Train R² = 0.60, Val R² = 0.58\n\nThen you try a deeper network and get: Train R² = 0.95, Val R² = 0.50\n\nWhat does this tell you? Should you use the deeper model? Why or why not?\n",
        "\n",
        "**Hint**: The gap between train and val performance reveals overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 9 (Short Answer)\n",
        "\n",
        "**Question 9 - Learning Rate Impact on Metrics**\n\nYou train two models on the same data:\n- Model A (LR=0.001): Final MSE = 10.5 after 1000 epochs\n- Model B (LR=0.1): Final MSE = 45.2 after 1000 epochs\n\nWhat does this suggest about Model B's learning rate? How would you diagnose this?\n",
        "\n",
        "**Hint**: A learning rate that's too high causes instability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 10 (Short Answer)\n",
        "\n",
        "**Question 10 - Real-World Trade-offs**\n\nIn production, you must choose between:\n- Model A: Avg error $50,000 (but only $10,000 on cheap houses, $200,000 on mansions)\n- Model B: Avg error $60,000 (but consistent across all price ranges)\n\nWhich do you deploy? Explain your reasoning using metric selection concepts.\n",
        "\n",
        "**Hint**: This is about MSE vs MAE philosophy. Do you care more about average or consistency?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Submission\n",
        "\n",
        "Before submitting:\n",
        "1. Run all cells to ensure code executes without errors\n",
        "2. Check that all questions are answered\n",
        "3. Review your explanations for clarity\n",
        "\n",
        "**To Submit**:\n",
        "- File → Download → Download .ipynb\n",
        "- Submit the notebook file to your course LMS\n",
        "\n",
        "**Note**: Make sure your name is in the filename (e.g., homework_01_yourname.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}