{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 5: Autoencoders & Embeddings - Homework\\n",
        "\\n",
        "**ML2: Advanced Machine Learning**\\n",
        "\\n",
        "**Estimated Time**: 1 hour\\n",
        "\\n",
        "---\\n",
        "\\n",
        "This homework combines programming exercises and knowledge-based questions to reinforce this week's concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\\n",
        "\\n",
        "Run this cell to import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\\n",
        "import matplotlib.pyplot as plt\\n",
        "import torch\\n",
        "import torch.nn as nn\\n",
        "\\n",
        "# Set random seed for reproducibility\\n",
        "np.random.seed(42)\\n",
        "torch.manual_seed(42)\\n",
        "\\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\\n",
        "## Part 1: Programming Exercises (60%)\\n",
        "\\n",
        "Complete the following programming tasks. Read each description carefully and implement the requested functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Build a Simple Autoencoder\\n",
        "\\n",
        "**Time**: 20 min\\n",
        "\\n",
        "Implement an autoencoder for MNIST digit compression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch",
        "import torch.nn as nn",
        "",
        "class Autoencoder(nn.Module):",
        "    def __init__(self, input_dim=784, latent_dim=32):",
        "        super(Autoencoder, self).__init__()",
        "        # TODO: Define encoder",
        "        # TODO: Define decoder",
        "        pass",
        "    ",
        "    def forward(self, x):",
        "        # TODO: Encode and decode",
        "        pass",
        "",
        "# TODO: Train on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Visualize Latent Space\\n",
        "\\n",
        "**Time**: 20 min\\n",
        "\\n",
        "Extract and visualize the learned latent representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt",
        "from sklearn.manifold import TSNE",
        "",
        "# TODO: Encode test images to latent space",
        "# TODO: Use t-SNE to reduce to 2D",
        "# TODO: Plot colored by digit class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\\n",
        "## Part 2: Knowledge Questions (40%)\\n",
        "\\n",
        "Answer the following questions to test your conceptual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 (Multiple Choice)\\n",
        "\\n",
        "What is the main purpose of the bottleneck layer in an autoencoder?\\n",
        "\\n",
        "A) To slow down training\\n",
        "B) To force compression and learn important features\\n",
        "C) To increase model capacity\\n",
        "D) To prevent overfitting only\\n",
        "\\n",
        "**Hint**: Why do we make the latent dimension smaller than the input?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\\n",
        "\\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2 (Short Answer)\\n",
        "\\n",
        "How do Variational Autoencoders (VAEs) differ from standard autoencoders? What additional capability do they have?\\n",
        "\\n",
        "**Hint**: Think about Point estimates vs distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\\n",
        "\\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\\n",
        "## Submission\\n",
        "\\n",
        "Before submitting:\\n",
        "1. Run all cells to ensure code executes without errors\\n",
        "2. Check that all questions are answered\\n",
        "3. Review your explanations for clarity\\n",
        "\\n",
        "**To Submit**:\\n",
        "- File → Download → Download .ipynb\\n",
        "- Submit the notebook file to your course LMS\\n",
        "\\n",
        "**Note**: Make sure your name is in the filename (e.g., homework_01_yourname.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}