{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 10: Introduction to Large Language Models - Homework\n",
        "\n",
        "**ML2: Advanced Machine Learning**\n",
        "\n",
        "**Estimated Time**: 1 hour\n",
        "\n",
        "---\n",
        "\n",
        "This homework combines programming exercises and knowledge-based questions to reinforce this week's concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Run this cell to import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Programming Exercises (60%)\n",
        "\n",
        "Complete the following programming tasks. Read each description carefully and implement the requested functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Experiment: Temperature and Sampling\n",
        "\n",
        "**Time**: 10 min\n",
        "\n",
        "Explore how temperature affects LLM output diversity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conceptual demonstration (pseudocode)\n",
        "# In reality, use OpenAI API\n",
        "\n",
        "# Temperature = 0.0 (deterministic, always picks most likely token)\n",
        "prompt = \"The capital of France is\"\n",
        "# Output: \"Paris\" (every time)\n",
        "\n",
        "# Temperature = 0.7 (balanced creativity)\n",
        "# Output: \"Paris\" (high probability)\n",
        "#         \"Paris, which is known for\" (medium probability)\n",
        "\n",
        "# Temperature = 1.5 (very creative/random)\n",
        "# Output: \"located in Europe\" (lower probability)\n",
        "#         \"a fascinating question\" (even lower probability)\n",
        "\n",
        "# TODO: Run experiments with different temperatures\n",
        "# Observe: Low temp = boring/repetitive, High temp = creative/nonsensical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Knowledge Questions (40%)\n",
        "\n",
        "Answer the following questions to test your conceptual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 (Short Answer)\n",
        "\n",
        "**Question 1 - Emergence from Scale**\n\nSmall language models (millions of parameters): Complete sentences\nLarge language models (billions of parameters): Reasoning, math, coding, translation\n\nEmergent abilities = capabilities that appear suddenly at scale, not present in smaller models.\n\nExplain:\n1. Why does scale enable new capabilities?\n2. Is this just \"more data\" or something fundamental?\n3. What surprised researchers about GPT-3's abilities?\n",
        "\n",
        "**Hint**: Scale allows models to capture more complex patterns and relationships in data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2 (Short Answer)\n",
        "\n",
        "**Question 2 - Pretraining vs Fine-tuning**\n\nPretraining: Learn language on massive unlabeled text (\"predict next word\")\nFine-tuning: Adapt to specific tasks with labeled data\n\nExplain:\n1. Why is pretraining on unlabeled data so powerful?\n2. What does the model learn during pretraining?\n3. How does fine-tuning leverage this?\n",
        "\n",
        "**Hint**: Pretraining = general language understanding. Fine-tuning = task specialization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3 (Multiple Choice)\n",
        "\n",
        "**Question 3 - Temperature Parameter**\n\nTemperature controls how the model samples from its probability distribution.\n\nWhat happens with temperature = 0?\n\nA) Random outputs\nB) Always selects the most likely next token (deterministic)\nC) Model stops working\nD) Longer responses\n",
        "\n",
        "A) Random outputs\n",
        "B) Always selects the most likely next token (deterministic)\n",
        "C) Model stops working\n",
        "D) Longer responses\n",
        "\n",
        "**Hint**: Temp=0 → greedily pick highest probability token every time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 4 (Short Answer)\n",
        "\n",
        "**Question 4 - Context Window Limitations**\n\nGPT-4 has a ~8k-128k token context window (depending on version).\n\nExplain:\n1. What happens when your conversation exceeds the context window?\n2. Why can't we just make infinite context windows?\n3. How does this affect long document summarization?\n",
        "\n",
        "**Hint**: Attention is O(n²) in sequence length. Memory and computation explode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5 (Short Answer)\n",
        "\n",
        "**Question 5 - In-Context Learning**\n\nYou can teach GPT new tasks by providing examples IN THE PROMPT (no fine-tuning needed).\n\nExample:\nPrompt: \"Translate to French: Hello → Bonjour, Goodbye → Au revoir, Thank you → \"\nOutput: \"Merci\"\n\nExplain:\n1. How does the model \"learn\" from these examples without training?\n2. Why is this a game-changer for NLP?\n3. What are the limits?\n",
        "\n",
        "**Hint**: The model recognizes the pattern at inference time, leveraging its pretraining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 6 (Multiple Choice)\n",
        "\n",
        "**Question 6 - Tokenization**\n\nLLMs don't process characters or words—they process TOKENS.\n\nWhat is a token?\n\nA) Always one word\nB) Always one character  \nC) A subword unit (could be part of word, whole word, or punctuation)\nD) A sentence\n",
        "\n",
        "A) Always one word\n",
        "B) Always one character\n",
        "C) A subword unit (could be part of word, whole word, or punctuation)\n",
        "D) A sentence\n",
        "\n",
        "**Hint**: \"ChatGPT\" might be 2 tokens: \"Chat\" + \"GPT\". Tokenization is subword-based."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 7 (Short Answer)\n",
        "\n",
        "**Question 7 - Hallucinations**\n\nLLMs sometimes generate plausible-sounding but factually incorrect information.\n\nExplain:\n1. Why do hallucinations happen?\n2. Is this fundamentally fixable, or inherent to the approach?\n3. How can you reduce hallucinations in practice?\n",
        "\n",
        "**Hint**: LLMs predict plausible text, not necessarily true text. They don't have a \"fact database\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 8 (Short Answer)\n",
        "\n",
        "**Question 8 - RLHF (Reinforcement Learning from Human Feedback)**\n\nChatGPT uses RLHF to align with human preferences.\n\nProcess:\n1. Collect human rankings of model outputs\n2. Train reward model to predict human preferences\n3. Fine-tune LLM to maximize reward\n\nExplain: Why is this better than just supervised fine-tuning on human demonstrations?\n",
        "\n",
        "**Hint**: RLHF allows learning from comparisons (\"A is better than B\"), not just demonstrations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 9 (Short Answer)\n",
        "\n",
        "**Question 9 - Zero-Shot vs Few-Shot**\n\nZero-shot: \"Classify sentiment: 'I love this!' → \"\nFew-shot: \"Positive: 'Great!' Negative: 'Terrible!' Classify: '  I love this!' → \"\n\nExplain:\n1. When does few-shot help significantly?\n2. When is zero-shot sufficient?\n3. What does this reveal about what LLMs learned during pretraining?\n",
        "\n",
        "**Hint**: LLMs have general capabilities. Few-shot refines them for specific formats/tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 10 (Short Answer)\n",
        "\n",
        "**Question 10 - Scaling Laws**\n\nResearch shows that LLM performance follows predictable scaling laws:\nPerformance = f(model_size, data_size, compute)\n\nExplain:\n1. What does this predict about future models?\n2. What are the bottlenecks to continued scaling?\n3. Is \"bigger is always better\" sustainable?\n",
        "\n",
        "**Hint**: Bottlenecks: compute cost, energy, data availability, diminishing returns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Submission\n",
        "\n",
        "Before submitting:\n",
        "1. Run all cells to ensure code executes without errors\n",
        "2. Check that all questions are answered\n",
        "3. Review your explanations for clarity\n",
        "\n",
        "**To Submit**:\n",
        "- File → Download → Download .ipynb\n",
        "- Submit the notebook file to your course LMS\n",
        "\n",
        "**Note**: Make sure your name is in the filename (e.g., homework_01_yourname.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}