{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 12: Retrieval Augmented Generation (RAG) - Homework\n",
        "\n",
        "**ML2: Advanced Machine Learning**\n",
        "\n",
        "**Estimated Time**: 1 hour\n",
        "\n",
        "---\n",
        "\n",
        "This homework combines programming exercises and knowledge-based questions to reinforce this week's concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Run this cell to import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Programming Exercises (60%)\n",
        "\n",
        "Complete the following programming tasks. Read each description carefully and implement the requested functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Experiment: RAG vs Non-RAG\n",
        "\n",
        "**Time**: 10 min\n",
        "\n",
        "Compare LLM responses with and without retrieved context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scenario: Company-specific Q&A\n",
        "\n",
        "# Document database (simplified)\n",
        "docs = [\n",
        "    \"Acme Corp vacation policy: 15 days PER year for new employees.\",\n",
        "    \"Acme Corp allows remote work 3 days per week.\",\n",
        "    \"Acme Corp health insurance covers dental.\"\n",
        "]\n",
        "\n",
        "question = \"How many vacation days do new employees get?\"\n",
        "\n",
        "# WITHOUT RAG:\n",
        "prompt_no_rag = f\"Question: {question}\"\n",
        "# LLM might hallucinate or give generic answer\n",
        "\n",
        "# WITH RAG:\n",
        "# 1. Retrieve relevant docs\n",
        "relevant_doc = docs[0]  # (in reality, use embedding similarity)\n",
        "\n",
        "# 2. Augment prompt\n",
        "prompt_with_rag = f\"\"\"Context: {relevant_doc}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer based on the context:\"\"\"\n",
        "# LLM gives accurate, grounded answer\n",
        "\n",
        "# TODO: Compare outputs. RAG provides factual, specific answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Knowledge Questions (40%)\n",
        "\n",
        "Answer the following questions to test your conceptual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 (Short Answer)\n",
        "\n",
        "**Question 1 - Why RAG?**\n\nLLMs have knowledge cutoff dates and can't access private/proprietary data.\n\nExplain:\n1. How does RAG solve these problems?\n2. What's the alternative to RAG (fine-tuning)?\n3. When would you choose RAG over fine-tuning?\n",
        "\n",
        "**Hint**: RAG = retrieve + inject context. Fine-tuning = retrain model. RAG is more flexible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2 (Short Answer)\n",
        "\n",
        "**Question 2 - RAG Pipeline**\n\nRAG pipeline:\n1. Embed documents into vector database\n2. Embed user query\n3. Retrieve top-k most similar documents\n4. Inject into LLM prompt\n5. Generate answer\n\nExplain: Why is embedding similarity better than keyword matching for retrieval?\n",
        "\n",
        "**Hint**: Embeddings capture semantic meaning. \"car\" and \"automobile\" are similar in embedding space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3 (Multiple Choice)\n",
        "\n",
        "**Question 3 - Chunk Size Tradeoff**\n\nYou're splitting documents into chunks for RAG. Should chunks be:\n\nA) Very small (1 sentence) - precise but lacks context\nB) Very large (entire documents) - contextual but noisy\nC) Medium (paragraphs) - balances precision and context\nD) Size doesn't matter\n",
        "\n",
        "A) Very small (1 sentence) - precise but lacks context\n",
        "B) Very large (entire documents) - contextual but noisy\n",
        "C) Medium (paragraphs) - balances precision and context\n",
        "D) Size doesn't matter\n",
        "\n",
        "**Hint**: Too small = missing context. Too large = irrelevant information. Balance is key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 4 (Short Answer)\n",
        "\n",
        "**Question 4 - Vector Databases**\n\nRAG systems use vector databases (Pinecone, Weaviate, Chroma).\n\nExplain:\n1. What makes them different from traditional databases?\n2. What operation do they optimize for?\n3. Why can't you just use PostgreSQL?\n",
        "\n",
        "**Hint**: Vector DBs optimize for similarity search (nearest neighbors), not exact matches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5 (Short Answer)\n",
        "\n",
        "**Question 5 - Top-k Retrieval**\n\nYou retrieve the top-k most similar documents. What's k?\n\nExplain:\n1. What happens if k is too small (e.g., k=1)?\n2. What happens if k is too large (e.g., k=100)?\n3. How do you choose k?\n",
        "\n",
        "**Hint**: Too small = miss relevant info. Too large = noise + context window limit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 6 (Multiple Choice)\n",
        "\n",
        "**Question 6 - Hallucination Reduction**\n\nRAG reduces hallucinations because:\n\nA) It makes the model larger\nB) It grounds responses in retrieved factual documents\nC) It uses higher temperature\nD) It eliminates all errors\n",
        "\n",
        "A) It makes the model larger\n",
        "B) It grounds responses in retrieved factual documents\n",
        "C) It uses higher temperature\n",
        "D) It eliminates all errors\n",
        "\n",
        "**Hint**: RAG provides evidence. LLM is instructed to answer from evidence, not make things up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 7 (Short Answer)\n",
        "\n",
        "**Question 7 - Retrieval Metrics**\n\nHow do you measure retrieval quality?\n\n- Precision @ k: Fraction of top-k that are relevant\n- Recall @ k: Fraction of ALL relevant docs in top-k\n- MRR: Mean reciprocal rank of first relevant doc\n\nExplain: Why might you want high recall even if precision is lower?\n",
        "\n",
        "**Hint**: Better to retrieve extra documents than miss THE crucial one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 8 (Short Answer)\n",
        "\n",
        "**Question 8 - Hybrid Search**\n\nHybrid search = semantic search (embeddings) + keyword search (BM25)\n\nExplain:\n1. Why combine both?\n2. When does keyword search outperform semantic search?\n3. How do you merge the results?\n",
        "\n",
        "**Hint**: Semantic = meaning. Keyword = exact terms. Combine for robustness. Merge with weighted scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 9 (Short Answer)\n",
        "\n",
        "**Question 9 - Metadata Filtering**\n\nBefore semantic search, filter by metadata:\n- Date range\n- Author\n- Document type\n\nExplain: Why filter first instead of just retrieving everything?\n",
        "\n",
        "**Hint**: Filtering reduces search space, improves relevance, respects permissions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 10 (Short Answer)\n",
        "\n",
        "**Question 10 - Real-World Application**\n\nCustomer support chatbot with RAG:\n- Vector DB: Company knowledge base, FAQs, docs\n- Query: Customer question\n- Retrieve + Generate: Grounded answer\n\nExplain:\n1. What advantage does this have over traditional keyword search?\n2. What happens when documents are updated?\n3. How do you handle multi-step questions?\n",
        "\n",
        "**Hint**: Semantic search understands intent. Update embeddings when docs change. Multi-step = multiple retrievals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Submission\n",
        "\n",
        "Before submitting:\n",
        "1. Run all cells to ensure code executes without errors\n",
        "2. Check that all questions are answered\n",
        "3. Review your explanations for clarity\n",
        "\n",
        "**To Submit**:\n",
        "- File → Download → Download .ipynb\n",
        "- Submit the notebook file to your course LMS\n",
        "\n",
        "**Note**: Make sure your name is in the filename (e.g., homework_01_yourname.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}