{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 1: Introduction to Deep Learning - Homework\n",
        "\n",
        "**ML2: Advanced Machine Learning**\n",
        "\n",
        "**Estimated Time**: 1 hour\n",
        "\n",
        "---\n",
        "\n",
        "This homework combines programming exercises and knowledge-based questions to reinforce this week's concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Run this cell to import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Programming Exercises (60%)\n",
        "\n",
        "Complete the following programming tasks. Read each description carefully and implement the requested functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Experiment: Observing Feature Learning\n",
        "\n",
        "**Time**: 8 min\n",
        "\n",
        "Run this code to visualize what happens when a network learns features automatically vs. using hand-crafted features. Observe the outputs and answer the reflection questions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Simulate a simple pattern recognition task\n",
        "# Pattern: Detect if sum of inputs > 5\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Generate data\n",
        "X = torch.randn(100, 4)  # 100 samples, 4 features\n",
        "y = (X.sum(dim=1) > 0).float()  # Label: 1 if sum > 0, else 0\n",
        "\n",
        "# Network that LEARNS features\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 8),   # Learned feature extraction\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Train for a few steps\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X).squeeze()\n",
        "    loss = loss_fn(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f\"Final loss: {loss.item():.4f}\")\n",
        "print(f\"First layer weights (learned features):\")\n",
        "print(model[0].weight.data)\n",
        "\n",
        "# TODO: After running, answer reflection questions below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Experiment: Network Without Nonlinearity\n",
        "\n",
        "**Time**: 10 min\n",
        "\n",
        "This experiment demonstrates why activation functions are essential. Compare two networks: one with ReLU, one without."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Network WITH nonlinearity (ReLU)\n",
        "network_with_relu = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 15),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(15, 5)\n",
        ")\n",
        "\n",
        "# Network WITHOUT nonlinearity (just linear layers)\n",
        "network_without_relu = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.Linear(20, 15),\n",
        "    nn.Linear(15, 5)\n",
        ")\n",
        "\n",
        "# Test input\n",
        "x = torch.randn(1, 10)\n",
        "\n",
        "# Compare outputs\n",
        "output_with = network_with_relu(x)\n",
        "output_without = network_without_relu(x)\n",
        "\n",
        "print(\"With ReLU output:\", output_with)\n",
        "print(\"Without ReLU output:\", output_without)\n",
        "\n",
        "# TODO: Now manually compute what network_without_relu is equivalent to\n",
        "# Hint: Multiple linear transformations collapse into a single linear transformation\n",
        "# Can you express the 3-layer linear network as a SINGLE equivalent linear layer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Knowledge Questions (40%)\n",
        "\n",
        "Answer the following questions to test your conceptual understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1 (Short Answer)\n",
        "\n",
        "**Question 1 - Automatic Feature Learning (Conceptual)**\n\nTraditional machine learning for image classification requires manually designing features (e.g., edge detectors, color histograms, texture filters). Deep learning does not.\n\nExplain in 3-4 sentences:\n1. WHY can deep networks learn features automatically?\n2. WHAT enables this (what architectural property)?\n3. What is the tradeoff (what does deep learning need more of)?\n",
        "\n",
        "**Hint**: Think about what happens in each layer of a deep network and how backpropagation adjusts those layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2 (Short Answer)\n",
        "\n",
        "**Question 2 - Feature Hierarchy (Conceptual)**\n\nIn a deep CNN for face recognition:\n- Layer 1 might detect edges\n- Layer 2 might detect facial features (eyes, nose)\n- Layer 3 might detect whole faces\n\nExplain: Why does depth create this hierarchy? What would happen if you used a single-layer network instead?\n",
        "\n",
        "**Hint**: Consider how each layer builds on representations from the previous layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3 (Short Answer)\n",
        "\n",
        "**Question 3 - Nonlinearity Experiment Reflection**\n\nBased on the 'Network Without Nonlinearity' experiment above:\n\nProve mathematically or explain conceptually why the 3-layer network without ReLU is equivalent to a SINGLE linear layer. What does this tell you about the necessity of activation functions?\n",
        "\n",
        "**Hint**: Remember: Linear(Linear(x)) = Linear(x) because you can multiply weight matrices together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 4 (Multiple Choice)\n",
        "\n",
        "**Question 4 - Understanding Nonlinearity**\n\nA neural network with 10 layers but NO activation functions can represent:\n\nA) Any possible function (universal approximation)\nB) Only linear functions\nC) Only polynomial functions\nD) Only step functions\n",
        "\n",
        "A) Any possible function (universal approximation)\n",
        "B) Only linear functions\n",
        "C) Only polynomial functions\n",
        "D) Only step functions\n",
        "\n",
        "**Hint**: What happens when you compose linear transformations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5 (Short Answer)\n",
        "\n",
        "**Question 5 - ReLU Design Choice**\n\nReLU(x) = max(0, x) is one of the simplest possible nonlinear functions. Yet it became the dominant activation function (replacing sigmoid).\n\nExplain TWO advantages ReLU has over sigmoid for deep networks. One should relate to gradients, one to computation.\n",
        "\n",
        "**Hint**: Think about what happens to gradients when x is large and positive in sigmoid vs ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 6 (Short Answer)\n",
        "\n",
        "**Question 6 - Gradient Descent Intuition**\n\nGradient descent updates weights using: θ_new = θ_old - α × ∇L\n\nWhere ∇L is the gradient of the loss.\n\nExplain in simple terms:\n1. What does the gradient ∇L represent geometrically?\n2. Why do we SUBTRACT it (the negative sign)?\n3. What role does α (learning rate) play?\n",
        "\n",
        "**Hint**: Think of the loss function as a landscape/terrain you're trying to navigate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 7 (Multiple Choice)\n",
        "\n",
        "**Question 7 - Loss Function Purpose**\n\nThe loss function in deep learning serves to:\n\nA) Measure how wrong the model is, providing a signal for gradient descent\nB) Prevent overfitting by penalizing complex models\nC) Speed up training by reducing computation\nD) Automatically select which features to learn\n",
        "\n",
        "A) Measure how wrong the model is, providing a signal for gradient descent\n",
        "B) Prevent overfitting by penalizing complex models\n",
        "C) Speed up training by reducing computation\n",
        "D) Automatically select which features to learn\n",
        "\n",
        "**Hint**: What do we need to compute gradients?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**: [Write your answer here - e.g., 'B']\n",
        "\n",
        "**Explanation**: [Explain why this is correct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 8 (Short Answer)\n",
        "\n",
        "**Question 8 - Feature Learning Reflection**\n\nAfter running the 'Observing Feature Learning' experiment:\n\nLook at the learned weights in the first layer. These represent the FEATURES the network learned.\n\nExplain: How did the network 'know' which features to learn? What guided it to learn useful features rather than random ones?\n",
        "\n",
        "**Hint**: The answer involves both the loss function and backpropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 9 (Short Answer)\n",
        "\n",
        "**Question 9 - Connecting the Concepts**\n\nIntegrate all three key insights:\n\nExplain how (1) automatic feature learning, (2) nonlinearity, and (3) gradient descent work TOGETHER to enable deep learning. \n\nYour answer should show how all three are necessary and how they interact.\n",
        "\n",
        "**Hint**: Think: What would happen if you removed any one of these three components?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 10 (Short Answer)\n",
        "\n",
        "**Question 10 - Scaling to Real Problems**\n\nImageNet (image classification) has 1000 classes and ~1.2 million training images. Traditional ML would require human experts to manually design thousands of features.\n\nExplain: Why does deep learning have an advantage that GROWS as the problem gets more complex (more classes, more data)? What breaks down in the traditional approach?\n",
        "\n",
        "**Hint**: Consider both the human effort required and what happens when you have more data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Answer**:\n",
        "\n",
        "[Write your answer here in 2-4 sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Submission\n",
        "\n",
        "Before submitting:\n",
        "1. Run all cells to ensure code executes without errors\n",
        "2. Check that all questions are answered\n",
        "3. Review your explanations for clarity\n",
        "\n",
        "**To Submit**:\n",
        "- File → Download → Download .ipynb\n",
        "- Submit the notebook file to your course LMS\n",
        "\n",
        "**Note**: Make sure your name is in the filename (e.g., homework_01_yourname.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}