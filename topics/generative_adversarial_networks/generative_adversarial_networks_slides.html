<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generative Adversarial Networks</title>
    
    <!-- MathJax -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <!-- D3.js -->
    <script src="https://d3js.org/d3.v7.min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f8f9fa;
            color: #2c3e50;
            overflow: hidden;
        }

        .presentation {
            width: 100vw;
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .slide {
            display: none;
            width: 85vw;
            max-width: 1000px;
            height: 75vh;
            background: white;
            border-radius: 8px;
            padding: 30px;
            box-shadow: 0 2px 20px rgba(0,0,0,0.1);
            overflow-y: auto;
            position: absolute;
        }

        .slide.active {
            display: block;
            position: relative;
        }

        /* Typography */
        h1 {
            font-size: 2.2rem;
            font-weight: 300;
            color: #2c3e50;
            margin-bottom: 1.2rem;
            line-height: 1.2;
        }

        h2 {
            font-size: 1.7rem;
            font-weight: 300;
            color: #2c3e50;
            margin-bottom: 1.2rem;
            line-height: 1.3;
        }

        h3 {
            font-size: 1.2rem;
            font-weight: 400;
            color: #34495e;
            margin-bottom: 0.8rem;
        }

        h4 {
            font-size: 1rem;
            font-weight: 500;
            color: #34495e;
            margin-bottom: 0.5rem;
        }

        p {
            font-size: 0.9rem;
            line-height: 1.4;
            color: #5a6c7d;
            margin-bottom: 1rem;
        }

        ul {
            list-style: none;
            margin-bottom: 1rem;
        }

        li {
            font-size: 0.9rem;
            line-height: 1.4;
            color: #5a6c7d;
            margin-bottom: 0.5rem;
            padding-left: 1.5rem;
            position: relative;
        }

        li::before {
            content: "•";
            color: #3498db;
            position: absolute;
            left: 0;
            font-size: 1.2rem;
        }

        /* Layout classes - no colored boxes */
        .grid-2 {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            align-items: start;
        }

        .grid-3 {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 1.5rem;
            align-items: start;
        }

        /* Simple content blocks */
        .concept-box {
            background: #f8f9fa;
            padding: 1.2rem;
            border-radius: 4px;
            margin: 1rem 0;
            border-left: 4px solid #95a5a6;
        }

        .formula-section {
            background: #fdfdfd;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 1.5rem;
            margin: 1rem 0;
            text-align: center;
        }

        .network-diagram {
            background: #f8f9fa;
            border-radius: 4px;
            padding: 1.5rem;
            margin: 1rem 0;
            text-align: center;
        }

        /* Title slide styling */
        .title-slide {
            text-align: center;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .title-slide h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            color: #2c3e50;
        }

        .subtitle {
            font-size: 1.3rem;
            color: #7f8c8d;
            margin-bottom: 2rem;
        }

        .objectives {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1.5rem;
            max-width: 800px;
            margin: 0 auto;
        }

        .objective {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 4px;
            border-left: 4px solid #3498db;
        }

        .objective h3 {
            color: #3498db;
            margin-bottom: 0.5rem;
        }

        /* Architecture layouts */
        .adversarial-setup {
            display: grid;
            grid-template-columns: 1fr auto 1fr;
            gap: 2rem;
            align-items: center;
            margin: 2rem 0;
        }

        .network-box {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 4px;
            text-align: center;
            border: 2px solid #bdc3c7;
        }

        .versus {
            font-size: 2rem;
            font-weight: bold;
            color: #34495e;
        }

        /* Process flow */
        .training-flow {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin: 1.5rem 0;
        }

        .flow-step {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 4px;
            text-align: center;
            flex: 1;
            margin: 0 0.5rem;
            border-left: 4px solid #3498db;
        }

        .arrow {
            font-size: 1.5rem;
            color: #7f8c8d;
        }

        /* Comparison tables - simple styling */
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }

        .comparison-table th {
            background: #ecf0f1;
            padding: 0.8rem;
            text-align: left;
            border-bottom: 2px solid #bdc3c7;
            color: #2c3e50;
        }

        .comparison-table td {
            padding: 0.8rem;
            border-bottom: 1px solid #ecf0f1;
            color: #5a6c7d;
        }

        /* Visualization */
        .viz {
            border: 1px solid #e8e8e8;
            border-radius: 4px;
            padding: 0.8rem;
            margin: 0.8rem 0;
            background: white;
            min-height: 250px;
        }

        /* Navigation */
        .counter {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: #34495e;
            color: white;
            padding: 10px 15px;
            border-radius: 20px;
            font-size: 14px;
        }

        .nav-button {
            position: fixed;
            bottom: 20px;
            background: #34495e;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 14px;
        }

        .nav-button:hover {
            background: #2c3e50;
        }

        .prev {
            left: 20px;
        }

        .next {
            left: 80px;
        }
    </style>
</head>
<body>
    <div class="presentation">
        <!-- Slide 1: Title -->
        <div class="slide active title-slide" id="slide1">
            <h1>Generative Adversarial Networks</h1>
            <p class="subtitle">The Art of Learning Through Competition</p>
            
            <div class="objectives">
                <div class="objective">
                    <h3>Adversarial Framework</h3>
                    <p>Master the two-player game between generator and discriminator</p>
                </div>
                <div class="objective">
                    <h3>Training Dynamics</h3>
                    <p>Understand minimax optimization and stability challenges</p>
                </div>
                <div class="objective">
                    <h3>GAN Variants</h3>
                    <p>Explore DCGAN, WGAN, and conditional approaches</p>
                </div>
                <div class="objective">
                    <h3>Real Applications</h3>
                    <p>Learn practical uses from image synthesis to data augmentation</p>
                </div>
            </div>
        </div>

        <!-- Slide 2: The Core Concept -->
        <div class="slide" id="slide2">
            <h2>GANs: Learning Through Competition</h2>
            
            <div class="concept-box">
                <p><strong>Core Idea:</strong> Train two neural networks in competition - one generates fake data, the other tries to detect it. Through this adversarial process, the generator learns to create increasingly realistic data.</p>
            </div>
            
            <div class="adversarial-setup">
                <div class="network-box">
                    <h3>Generator</h3>
                    <p>Creates fake data</p>
                    <p>Noise → Realistic Data</p>
                </div>
                
                <div class="versus">VS</div>
                
                <div class="network-box">
                    <h3>Discriminator</h3>
                    <p>Detects fake data</p>
                    <p>Data → Real/Fake</p>
                </div>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Why This Works</h3>
                    <ul>
                        <li>Generator improves by fooling discriminator</li>
                        <li>Discriminator improves by catching fakes</li>
                        <li>Competition drives both to excel</li>
                        <li>No need for explicit similarity metrics</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Real-World Analogy</h3>
                    <p>Like a counterfeiter (generator) and detective (discriminator). The counterfeiter gets better at making fake money by learning from the detective's feedback, while the detective gets better at spotting fakes.</p>
                    
                    <div class="viz" id="adversarial-process-viz"></div>
                </div>
            </div>
        </div>

        <!-- Slide 3: Mathematical Foundation -->
        <div class="slide" id="slide3">
            <h2>The Minimax Game</h2>
            
            <div class="formula-section">
                <h3>GAN Objective Function</h3>
                <p>$$\min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]$$</p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Discriminator's Goal (Maximize)</h3>
                    <ul>
                        <li><strong>Real data:</strong> Output close to 1</li>
                        <li><strong>Fake data:</strong> Output close to 0</li>
                        <li>Maximize $\log D(x) + \log(1-D(G(z)))$</li>
                        <li>Perfect discriminator: $D(x) = 1$, $D(G(z)) = 0$</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Generator's Goal (Minimize)</h3>
                    <ul>
                        <li>Make discriminator confused</li>
                        <li>Want $D(G(z))$ close to 1</li>
                        <li>Minimize $\log(1-D(G(z)))$</li>
                        <li>Perfect generator: $D(G(z)) = 1$</li>
                    </ul>
                </div>
            </div>
            
            <div class="concept-box">
                <h4>Nash Equilibrium</h4>
                <p>At optimal solution: $D^*(x) = \frac{1}{2}$ everywhere, meaning the discriminator cannot distinguish real from fake data. The generator has learned the true data distribution.</p>
            </div>
        </div>

        <!-- Slide 4: Training Process -->
        <div class="slide" id="slide4">
            <h2>Training GANs</h2>
            
            <div class="training-flow">
                <div class="flow-step">
                    <h4>Step 1</h4>
                    <p>Train Discriminator</p>
                    <p>Fix G, update D</p>
                </div>
                <div class="arrow">→</div>
                <div class="flow-step">
                    <h4>Step 2</h4>
                    <p>Train Generator</p>
                    <p>Fix D, update G</p>
                </div>
                <div class="arrow">→</div>
                <div class="flow-step">
                    <h4>Repeat</h4>
                    <p>Alternate steps</p>
                    <p>Until convergence</p>
                </div>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Discriminator Training</h3>
                    <ul>
                        <li>Sample real data batch</li>
                        <li>Generate fake data batch</li>
                        <li>Compute loss for both</li>
                        <li>Backpropagate through D only</li>
                    </ul>
                    
                    <h3>Key Challenges</h3>
                    <ul>
                        <li>Balancing D and G strength</li>
                        <li>Preventing mode collapse</li>
                        <li>Avoiding vanishing gradients</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Generator Training</h3>
                    <ul>
                        <li>Generate fake data batch</li>
                        <li>Pass through frozen discriminator</li>
                        <li>Compute adversarial loss</li>
                        <li>Backpropagate through G only</li>
                    </ul>
                    
                    <div class="network-diagram">
                        <p><strong>Training Trick:</strong> Instead of minimizing $\log(1-D(G(z)))$, maximize $\log(D(G(z)))$ to avoid vanishing gradients early in training.</p>
                    </div>
                    
                    <div class="viz" id="training-loss-viz"></div>
                </div>
            </div>
        </div>

        <!-- Slide 5: DCGAN Architecture -->
        <div class="slide" id="slide5">
            <h2>Deep Convolutional GANs</h2>
            
            <div class="concept-box">
                <p><strong>DCGAN:</strong> The first successful deep convolutional GAN architecture that established architectural guidelines for stable training.</p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Generator Architecture</h3>
                    <ul>
                        <li><strong>Input:</strong> Random noise vector (100D)</li>
                        <li><strong>Upsampling:</strong> Transposed convolutions</li>
                        <li><strong>Normalization:</strong> Batch normalization (not in output)</li>
                        <li><strong>Activation:</strong> ReLU (Tanh in output)</li>
                        <li><strong>No pooling:</strong> Use strided convolutions</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Discriminator Architecture</h3>
                    <ul>
                        <li><strong>Input:</strong> Real or fake images</li>
                        <li><strong>Downsampling:</strong> Strided convolutions</li>
                        <li><strong>Normalization:</strong> Batch normalization (not in first layer)</li>
                        <li><strong>Activation:</strong> LeakyReLU</li>
                        <li><strong>Output:</strong> Single probability</li>
                    </ul>
                </div>
            </div>
            
            <div class="network-diagram">
                <h4>Key Design Principles</h4>
                <p>Replace pooling with strided convolutions • Use batch normalization • Remove fully connected layers • Use appropriate activations (ReLU/LeakyReLU)</p>
            </div>
        </div>

        <!-- Slide 6: Training Challenges -->
        <div class="slide" id="slide6">
            <h2>Common Training Problems</h2>
            
            <div class="grid-3">
                <div>
                    <h3>Mode Collapse</h3>
                    <p><strong>Problem:</strong> Generator produces limited variety</p>
                    <ul>
                        <li>All outputs look similar</li>
                        <li>Generator finds "easy" samples</li>
                        <li>Diversity loss in generated data</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Training Instability</h3>
                    <p><strong>Problem:</strong> Losses oscillate wildly</p>
                    <ul>
                        <li>Neither network converges</li>
                        <li>Quality varies dramatically</li>
                        <li>Hard to know when to stop</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Vanishing Gradients</h3>
                    <p><strong>Problem:</strong> Generator gets no signal</p>
                    <ul>
                        <li>Perfect discriminator gives no feedback</li>
                        <li>Generator cannot improve</li>
                        <li>Training stalls completely</li>
                    </ul>
                </div>
            </div>
            
            <h3>Solutions and Best Practices</h3>
            <div class="grid-2">
                <div>
                    <h4>Training Techniques</h4>
                    <ul>
                        <li>Feature matching for diversity</li>
                        <li>Mini-batch discrimination</li>
                        <li>Historical averaging</li>
                        <li>Different learning rates for G and D</li>
                    </ul>
                </div>
                
                <div>
                    <h4>Architecture Choices</h4>
                    <ul>
                        <li>Careful initialization</li>
                        <li>Spectral normalization</li>
                        <li>Progressive growing</li>
                        <li>Self-attention mechanisms</li>
                    </ul>
                </div>
            </div>
            
            <div class="viz" id="mode-collapse-viz"></div>
        </div>

        <!-- Slide 7: Wasserstein GAN -->
        <div class="slide" id="slide7">
            <h2>Wasserstein GAN: Better Training</h2>
            
            <div class="concept-box">
                <p><strong>Key Insight:</strong> Replace JS divergence with Wasserstein distance for more stable training and meaningful loss curves.</p>
            </div>
            
            <div class="formula-section">
                <h3>WGAN Objective</h3>
                <p>$$\min_G \max_{D \in \mathcal{D}} \mathbb{E}_{x \sim p_{data}}[D(x)] - \mathbb{E}_{z \sim p_z}[D(G(z))]$$</p>
                <p>Where $\mathcal{D}$ is the set of 1-Lipschitz functions</p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Advantages</h3>
                    <ul>
                        <li><strong>Meaningful loss:</strong> Correlates with sample quality</li>
                        <li><strong>No mode collapse:</strong> More stable training</li>
                        <li><strong>No saturation:</strong> Always provides gradients</li>
                        <li><strong>Hyperparameter robust:</strong> Less sensitive tuning</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Implementation</h3>
                    <ul>
                        <li><strong>No sigmoid:</strong> Discriminator outputs real values</li>
                        <li><strong>Weight clipping:</strong> Enforce Lipschitz constraint</li>
                        <li><strong>RMSprop:</strong> Instead of Adam optimizer</li>
                        <li><strong>More D updates:</strong> 5 critic updates per generator</li>
                    </ul>
                </div>
            </div>
            
            <div class="network-diagram">
                <h4>WGAN-GP Improvement</h4>
                <p>Replace weight clipping with gradient penalty for better enforcement of Lipschitz constraint: $\lambda \mathbb{E}_{x \sim p_{penalty}}[(||\nabla_x D(x)||_2 - 1)^2]$</p>
            </div>
            
            <div class="viz" id="wgan-comparison-viz"></div>
        </div>

        <!-- Slide 8: Conditional GANs -->
        <div class="slide" id="slide8">
            <h2>Conditional GANs</h2>
            
            <div class="concept-box">
                <p><strong>Controlled Generation:</strong> Add conditioning information to both generator and discriminator to control what gets generated.</p>
            </div>
            
            <div class="adversarial-setup">
                <div class="network-box">
                    <h3>Conditional Generator</h3>
                    <p>G(z, c) → fake data</p>
                    <p>z: noise, c: condition</p>
                </div>
                
                <div class="versus">+</div>
                
                <div class="network-box">
                    <h3>Conditional Discriminator</h3>
                    <p>D(x, c) → real/fake</p>
                    <p>x: data, c: condition</p>
                </div>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Conditioning Types</h3>
                    <ul>
                        <li><strong>Class labels:</strong> Generate specific digit/object</li>
                        <li><strong>Text descriptions:</strong> Generate from captions</li>
                        <li><strong>Attributes:</strong> Hair color, age, expression</li>
                        <li><strong>Other images:</strong> Style transfer, colorization</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Applications</h3>
                    <ul>
                        <li><strong>Image-to-image:</strong> Pix2Pix for photo editing</li>
                        <li><strong>Text-to-image:</strong> Generate from descriptions</li>
                        <li><strong>Data augmentation:</strong> Create labeled examples</li>
                        <li><strong>Style control:</strong> Artistic style generation</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 9: CycleGAN -->
        <div class="slide" id="slide9">
            <h2>CycleGAN: Unpaired Translation</h2>
            
            <div class="concept-box">
                <p><strong>Problem:</strong> Learn mapping between two domains without paired training examples (e.g., horses ↔ zebras, photos ↔ paintings).</p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Architecture</h3>
                    <ul>
                        <li><strong>Two Generators:</strong> G: X→Y, F: Y→X</li>
                        <li><strong>Two Discriminators:</strong> D_X, D_Y</li>
                        <li><strong>Cycle Consistency:</strong> F(G(x)) ≈ x</li>
                        <li><strong>Identity Mapping:</strong> G(y) ≈ y when needed</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Loss Components</h3>
                    <ul>
                        <li><strong>Adversarial Loss:</strong> Realistic generation</li>
                        <li><strong>Cycle Loss:</strong> Preserve content</li>
                        <li><strong>Identity Loss:</strong> Preserve domain characteristics</li>
                    </ul>
                </div>
            </div>
            
            <div class="formula-section">
                <h4>Cycle Consistency Loss</h4>
                <p>$$L_{cyc}(G,F) = \mathbb{E}_{x \sim p_{data}(x)}[||F(G(x)) - x||_1] + \mathbb{E}_{y \sim p_{data}(y)}[||G(F(y)) - y||_1]$$</p>
            </div>
            
            <div class="network-diagram">
                <p><strong>Key Applications:</strong> Photo enhancement • Style transfer • Season change • Domain adaptation • Medical imaging</p>
            </div>
        </div>

        <!-- Slide 10: Evaluation Challenges -->
        <div class="slide" id="slide10">
            <h2>Evaluating GANs</h2>
            
            <div class="concept-box">
                <p><strong>Challenge:</strong> How do you measure the quality of generated samples? Unlike supervised learning, there's no ground truth to compare against.</p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Automatic Metrics</h3>
                    <h4>Inception Score (IS)</h4>
                    <ul>
                        <li>Measures diversity and quality</li>
                        <li>Uses pre-trained classifier</li>
                        <li>Higher is better</li>
                    </ul>
                    
                    <h4>Fréchet Inception Distance (FID)</h4>
                    <ul>
                        <li>Compares feature distributions</li>
                        <li>More robust than IS</li>
                        <li>Lower is better</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Human Evaluation</h3>
                    <ul>
                        <li><strong>Visual Quality:</strong> How realistic do images look?</li>
                        <li><strong>Diversity:</strong> How varied are the generated samples?</li>
                        <li><strong>Semantic Consistency:</strong> Do conditional outputs match conditions?</li>
                    </ul>
                    
                    <h4>Evaluation Challenges</h4>
                    <ul>
                        <li>Metrics don't capture all aspects</li>
                        <li>Different tasks need different metrics</li>
                        <li>Human evaluation is expensive</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 11: Applications -->
        <div class="slide" id="slide11">
            <h2>Real-World Applications</h2>
            
            <div class="grid-3">
                <div>
                    <h3>Content Creation</h3>
                    <ul>
                        <li>Synthetic faces (StyleGAN)</li>
                        <li>Art and design generation</li>
                        <li>Video game asset creation</li>
                        <li>Architecture and product design</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Data Augmentation</h3>
                    <ul>
                        <li>Medical imaging datasets</li>
                        <li>Rare class generation</li>
                        <li>Privacy-preserving synthetics</li>
                        <li>Simulation data generation</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Image Processing</h3>
                    <ul>
                        <li>Super-resolution (SRGAN)</li>
                        <li>Colorization of old photos</li>
                        <li>Inpainting and restoration</li>
                        <li>Style transfer applications</li>
                    </ul>
                </div>
            </div>
            
            <h3>Industry Impact</h3>
            <div class="grid-2">
                <div>
                    <h4>Creative Industries</h4>
                    <ul>
                        <li>Film and animation studios</li>
                        <li>Fashion and design</li>
                        <li>Gaming and entertainment</li>
                        <li>Advertising and marketing</li>
                    </ul>
                </div>
                
                <div>
                    <h4>Technical Applications</h4>
                    <ul>
                        <li>Medical image analysis</li>
                        <li>Autonomous vehicle training</li>
                        <li>Cybersecurity and fraud detection</li>
                        <li>Scientific simulation</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 12: Ethical Considerations -->
        <div class="slide" id="slide12">
            <h2>Ethics and Future Directions</h2>
            
            <div class="grid-2">
                <div>
                    <h3>Ethical Concerns</h3>
                    <ul>
                        <li><strong>Deepfakes:</strong> Realistic but fake media</li>
                        <li><strong>Misinformation:</strong> Synthetic news and propaganda</li>
                        <li><strong>Privacy:</strong> Generating private information</li>
                        <li><strong>Bias:</strong> Reinforcing dataset biases</li>
                    </ul>
                    
                    <h4>Mitigation Strategies</h4>
                    <ul>
                        <li>Detection algorithms</li>
                        <li>Watermarking techniques</li>
                        <li>Responsible disclosure</li>
                        <li>Regulatory frameworks</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Future Research</h3>
                    <ul>
                        <li><strong>Training Stability:</strong> More robust algorithms</li>
                        <li><strong>Controllability:</strong> Better conditioning mechanisms</li>
                        <li><strong>Efficiency:</strong> Faster training and inference</li>
                        <li><strong>Evaluation:</strong> Better quality metrics</li>
                    </ul>
                    
                    <h4>Emerging Trends</h4>
                    <ul>
                        <li>Diffusion models competition</li>
                        <li>3D and video generation</li>
                        <li>Multimodal GANs</li>
                        <li>Few-shot generation</li>
                    </ul>
                </div>
            </div>
            
            <div class="concept-box">
                <h4>Key Takeaway</h4>
                <p>GANs revolutionized generative modeling and continue to push the boundaries of what's possible in AI creativity, but with great power comes great responsibility for ethical use.</p>
            </div>
        </div>
    </div>

    <!-- Navigation -->
    <div class="counter">
        <span id="current">1</span> / <span id="total">12</span>
    </div>

    <script>
        let currentSlide = 1;
        const totalSlides = 12;

        function showSlide(n) {
            const slides = document.querySelectorAll('.slide');
            if (n > totalSlides) currentSlide = 1;
            if (n < 1) currentSlide = totalSlides;
            
            slides.forEach(slide => slide.classList.remove('active'));
            document.getElementById(`slide${currentSlide}`).classList.add('active');
            document.getElementById('current').textContent = currentSlide;
        }

        function nextSlide() {
            currentSlide++;
            showSlide(currentSlide);
        }

        function prevSlide() {
            currentSlide--;
            showSlide(currentSlide);
        }

        // Keyboard navigation
        document.addEventListener('keydown', function(e) {
            if (e.key === 'ArrowRight' || e.key === ' ') {
                nextSlide();
            } else if (e.key === 'ArrowLeft') {
                prevSlide();
            }
        });

        // Initialize
        showSlide(currentSlide);

        // D3.js Visualizations
        function initAdversarialProcessViz() {
            const container = d3.select('#adversarial-process-viz');
            if (!container.empty()) {
                container.html('');
                
                const width = container.node().getBoundingClientRect().width;
                const height = 200;
                const margin = {top: 20, right: 40, bottom: 40, left: 60};
                
                const svg = container.append('svg')
                    .attr('width', width)
                    .attr('height', height);
                
                const innerWidth = width - margin.left - margin.right;
                const innerHeight = height - margin.top - margin.bottom;
                
                const g = svg.append('g')
                    .attr('transform', `translate(${margin.left},${margin.top})`);
                
                // Generate sample data showing oscillating competition
                const iterations = Array.from({length: 50}, (_, i) => i);
                const genLoss = iterations.map(i => 0.5 + 0.3 * Math.sin(i * 0.2) + Math.random() * 0.1);
                const discLoss = iterations.map(i => 0.5 - 0.3 * Math.sin(i * 0.2) + Math.random() * 0.1);
                
                const xScale = d3.scaleLinear()
                    .domain([0, 49])
                    .range([0, innerWidth]);
                
                const yScale = d3.scaleLinear()
                    .domain([0, 1])
                    .range([innerHeight, 0]);
                
                // Add axes
                g.append('g')
                    .attr('transform', `translate(0,${innerHeight})`)
                    .call(d3.axisBottom(xScale).ticks(5))
                    .append('text')
                    .attr('x', innerWidth / 2)
                    .attr('y', 35)
                    .attr('fill', 'black')
                    .style('font-size', '12px')
                    .text('Training Iteration');
                
                g.append('g')
                    .call(d3.axisLeft(yScale))
                    .append('text')
                    .attr('transform', 'rotate(-90)')
                    .attr('y', -40)
                    .attr('x', -innerHeight / 2)
                    .attr('fill', 'black')
                    .style('font-size', '12px')
                    .text('Loss');
                
                // Generator line
                const genLine = d3.line()
                    .x((d, i) => xScale(i))
                    .y(d => yScale(d))
                    .curve(d3.curveMonotoneX);
                
                g.append('path')
                    .datum(genLoss)
                    .attr('fill', 'none')
                    .attr('stroke', '#3498db')
                    .attr('stroke-width', 2)
                    .attr('d', genLine);
                
                // Discriminator line
                const discLine = d3.line()
                    .x((d, i) => xScale(i))
                    .y(d => yScale(d))
                    .curve(d3.curveMonotoneX);
                
                g.append('path')
                    .datum(discLoss)
                    .attr('fill', 'none')
                    .attr('stroke', '#e67e22')
                    .attr('stroke-width', 2)
                    .attr('d', discLine);
                
                // Legend
                const legend = g.append('g')
                    .attr('transform', `translate(${innerWidth - 120}, 20)`);
                
                legend.append('line')
                    .attr('x1', 0).attr('x2', 20)
                    .attr('y1', 0).attr('y2', 0)
                    .attr('stroke', '#3498db')
                    .attr('stroke-width', 2);
                
                legend.append('text')
                    .attr('x', 25).attr('y', 4)
                    .style('font-size', '12px')
                    .text('Generator');
                
                legend.append('line')
                    .attr('x1', 0).attr('x2', 20)
                    .attr('y1', 15).attr('y2', 15)
                    .attr('stroke', '#e67e22')
                    .attr('stroke-width', 2);
                
                legend.append('text')
                    .attr('x', 25).attr('y', 19)
                    .style('font-size', '12px')
                    .text('Discriminator');
            }
        }

        function initTrainingLossViz() {
            const container = d3.select('#training-loss-viz');
            if (!container.empty()) {
                container.html('');
                
                const width = container.node().getBoundingClientRect().width;
                const height = 200;
                const margin = {top: 20, right: 40, bottom: 40, left: 60};
                
                const svg = container.append('svg')
                    .attr('width', width)
                    .attr('height', height);
                
                const innerWidth = width - margin.left - margin.right;
                const innerHeight = height - margin.top - margin.bottom;
                
                const g = svg.append('g')
                    .attr('transform', `translate(${margin.left},${margin.top})`);
                
                // Show alternating training phases
                const phases = [
                    {name: 'Train D', x: 0, width: 80, color: '#e67e22'},
                    {name: 'Train G', x: 90, width: 80, color: '#3498db'},
                    {name: 'Train D', x: 180, width: 80, color: '#e67e22'},
                    {name: 'Train G', x: 270, width: 80, color: '#3498db'}
                ];
                
                const xScale = d3.scaleLinear()
                    .domain([0, 350])
                    .range([0, innerWidth]);
                
                phases.forEach(phase => {
                    g.append('rect')
                        .attr('x', xScale(phase.x))
                        .attr('y', 20)
                        .attr('width', xScale(phase.width))
                        .attr('height', 30)
                        .attr('fill', phase.color)
                        .attr('opacity', 0.3);
                    
                    g.append('text')
                        .attr('x', xScale(phase.x + phase.width/2))
                        .attr('y', 40)
                        .attr('text-anchor', 'middle')
                        .style('font-size', '12px')
                        .text(phase.name);
                });
                
                // Add arrows
                [1, 2, 3].forEach(i => {
                    const x = xScale(80 + i * 90);
                    g.append('path')
                        .attr('d', `M${x-10},35 L${x+10},35 M${x+5},30 L${x+10},35 L${x+5},40`)
                        .attr('stroke', '#7f8c8d')
                        .attr('stroke-width', 2)
                        .attr('fill', 'none');
                });
                
                g.append('text')
                    .attr('x', innerWidth / 2)
                    .attr('y', 15)
                    .attr('text-anchor', 'middle')
                    .style('font-size', '14px')
                    .style('font-weight', 'bold')
                    .text('Alternating Training Process');
            }
        }

        function initModeCollapseViz() {
            const container = d3.select('#mode-collapse-viz');
            if (!container.empty()) {
                container.html('');
                
                const width = container.node().getBoundingClientRect().width;
                const height = 160;
                
                const svg = container.append('svg')
                    .attr('width', width)
                    .attr('height', height);
                
                // Healthy diversity vs mode collapse
                const leftG = svg.append('g')
                    .attr('transform', 'translate(50, 20)');
                
                const rightG = svg.append('g')
                    .attr('transform', `translate(${width/2 + 50}, 20)`);
                
                // Healthy generation (diverse points)
                leftG.append('text')
                    .attr('x', 0).attr('y', 0)
                    .style('font-size', '14px')
                    .style('font-weight', 'bold')
                    .text('Healthy Training');
                
                const healthyData = Array.from({length: 30}, () => ({
                    x: Math.random() * 100,
                    y: Math.random() * 100
                }));
                
                leftG.selectAll('.healthy-point')
                    .data(healthyData)
                    .enter().append('circle')
                    .attr('class', 'healthy-point')
                    .attr('cx', d => d.x)
                    .attr('cy', d => d.y + 20)
                    .attr('r', 3)
                    .attr('fill', '#27ae60')
                    .attr('opacity', 0.7);
                
                // Mode collapse (clustered points)
                rightG.append('text')
                    .attr('x', 0).attr('y', 0)
                    .style('font-size', '14px')
                    .style('font-weight', 'bold')
                    .text('Mode Collapse');
                
                const collapsedData = Array.from({length: 30}, () => ({
                    x: 40 + Math.random() * 20,
                    y: 40 + Math.random() * 20
                }));
                
                rightG.selectAll('.collapsed-point')
                    .data(collapsedData)
                    .enter().append('circle')
                    .attr('class', 'collapsed-point')
                    .attr('cx', d => d.x)
                    .attr('cy', d => d.y + 20)
                    .attr('r', 3)
                    .attr('fill', '#e74c3c')
                    .attr('opacity', 0.7);
            }
        }

        function initWGANComparisonViz() {
            const container = d3.select('#wgan-comparison-viz');
            if (!container.empty()) {
                container.html('');
                
                const width = container.node().getBoundingClientRect().width;
                const height = 200;
                const margin = {top: 20, right: 40, bottom: 40, left: 60};
                
                const svg = container.append('svg')
                    .attr('width', width)
                    .attr('height', height);
                
                const innerWidth = width - margin.left - margin.right;
                const innerHeight = height - margin.top - margin.bottom;
                
                const g = svg.append('g')
                    .attr('transform', `translate(${margin.left},${margin.top})`);
                
                // Generate comparison data
                const iterations = Array.from({length: 40}, (_, i) => i);
                const vanillaLoss = iterations.map(i => 1.5 + 0.8 * Math.sin(i * 0.3) + Math.random() * 0.4);
                const wganLoss = iterations.map(i => Math.max(0, 1.0 - i * 0.02 + Math.random() * 0.1));
                
                const xScale = d3.scaleLinear()
                    .domain([0, 39])
                    .range([0, innerWidth]);
                
                const yScale = d3.scaleLinear()
                    .domain([0, 3])
                    .range([innerHeight, 0]);
                
                // Add axes
                g.append('g')
                    .attr('transform', `translate(0,${innerHeight})`)
                    .call(d3.axisBottom(xScale).ticks(5))
                    .append('text')
                    .attr('x', innerWidth / 2)
                    .attr('y', 35)
                    .attr('fill', 'black')
                    .style('font-size', '12px')
                    .text('Training Epochs');
                
                g.append('g')
                    .call(d3.axisLeft(yScale))
                    .append('text')
                    .attr('transform', 'rotate(-90)')
                    .attr('y', -40)
                    .attr('x', -innerHeight / 2)
                    .attr('fill', 'black')
                    .style('font-size', '12px')
                    .text('Loss');
                
                // Vanilla GAN line (unstable)
                const vanillaLine = d3.line()
                    .x((d, i) => xScale(i))
                    .y(d => yScale(d))
                    .curve(d3.curveMonotoneX);
                
                g.append('path')
                    .datum(vanillaLoss)
                    .attr('fill', 'none')
                    .attr('stroke', '#e74c3c')
                    .attr('stroke-width', 2)
                    .attr('d', vanillaLine);
                
                // WGAN line (stable)
                const wganLine = d3.line()
                    .x((d, i) => xScale(i))
                    .y(d => yScale(d))
                    .curve(d3.curveMonotoneX);
                
                g.append('path')
                    .datum(wganLoss)
                    .attr('fill', 'none')
                    .attr('stroke', '#27ae60')
                    .attr('stroke-width', 2)
                    .attr('d', wganLine);
                
                // Legend
                const legend = g.append('g')
                    .attr('transform', `translate(${innerWidth - 120}, 20)`);
                
                legend.append('line')
                    .attr('x1', 0).attr('x2', 20)
                    .attr('y1', 0).attr('y2', 0)
                    .attr('stroke', '#e74c3c')
                    .attr('stroke-width', 2);
                
                legend.append('text')
                    .attr('x', 25).attr('y', 4)
                    .style('font-size', '12px')
                    .text('Vanilla GAN');
                
                legend.append('line')
                    .attr('x1', 0).attr('x2', 20)
                    .attr('y1', 15).attr('y2', 15)
                    .attr('stroke', '#27ae60')
                    .attr('stroke-width', 2);
                
                legend.append('text')
                    .attr('x', 25).attr('y', 19)
                    .style('font-size', '12px')
                    .text('WGAN');
            }
        }

        // Initialize visualizations when slides are shown
        const originalShowSlide = showSlide;
        showSlide = function(n) {
            originalShowSlide(n);
            
            // Initialize visualizations based on current slide
            setTimeout(() => {
                if (currentSlide === 2) initAdversarialProcessViz();
                if (currentSlide === 4) initTrainingLossViz();
                if (currentSlide === 6) initModeCollapseViz();
                if (currentSlide === 7) initWGANComparisonViz();
            }, 100);
        };

        // Initialize current slide visualizations
        setTimeout(() => {
            if (currentSlide === 2) initAdversarialProcessViz();
            if (currentSlide === 4) initTrainingLossViz();
            if (currentSlide === 6) initModeCollapseViz();
            if (currentSlide === 7) initWGANComparisonViz();
        }, 100);
    </script>
</body>
</html>
