<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Boosting and Bagging</title>
    
    <!-- MathJax -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <!-- D3.js -->
    <script src="https://d3js.org/d3.v7.min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f8f9fa;
            color: #2c3e50;
            overflow: hidden;
        }

        .presentation {
            width: 100vw;
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .slide {
            display: none;
            width: 85vw;
            max-width: 1000px;
            height: 75vh;
            background: white;
            border-radius: 8px;
            padding: 30px;
            box-shadow: 0 2px 20px rgba(0,0,0,0.1);
            overflow-y: auto;
            position: absolute;
        }

        .slide.active {
            display: block;
            position: relative;
        }

        /* Typography */
        h1 {
            font-size: 2.4rem;
            font-weight: 300;
            color: #2c3e50;
            margin-bottom: 1.5rem;
            line-height: 1.2;
        }

        h2 {
            font-size: 1.9rem;
            font-weight: 300;
            color: #2c3e50;
            margin-bottom: 1.5rem;
            line-height: 1.3;
        }

        h3 {
            font-size: 1.3rem;
            font-weight: 400;
            color: #34495e;
            margin-bottom: 1rem;
        }

        p {
            font-size: 1rem;
            line-height: 1.5;
            color: #5a6c7d;
            margin-bottom: 1.2rem;
        }

        ul {
            list-style: none;
            margin-bottom: 1.5rem;
        }

        li {
            font-size: 1rem;
            line-height: 1.5;
            color: #5a6c7d;
            margin-bottom: 0.6rem;
            padding-left: 1.5rem;
            position: relative;
        }

        li::before {
            content: "•";
            color: #3498db;
            position: absolute;
            left: 0;
            font-size: 1.2rem;
        }

        /* Layout */
        .grid-2 {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            align-items: start;
        }

        .grid-3 {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 1.5rem;
            align-items: start;
        }

        /* Content blocks */
        .highlight {
            background: #ecf0f1;
            padding: 1.5rem;
            border-radius: 4px;
            border-left: 4px solid #3498db;
            margin: 1.5rem 0;
        }

        .formula {
            background: #fdfdfd;
            border: 1px solid #e8e8e8;
            border-radius: 4px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            text-align: center;
        }

        .example {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 1.2rem;
            margin: 1.2rem 0;
        }

        /* Visualization */
        .viz {
            border: 1px solid #e8e8e8;
            border-radius: 4px;
            padding: 1rem;
            margin: 1.2rem 0;
            background: white;
            min-height: 300px;
        }

        /* Title slide */
        .title-slide {
            text-align: center;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .title-slide h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
        }

        .subtitle {
            font-size: 1.2rem;
            color: #7f8c8d;
            margin-bottom: 2.5rem;
        }

        .objectives {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 1.5rem;
            max-width: 700px;
            margin: 0 auto;
        }

        .objective {
            background: #f8f9fa;
            padding: 1.2rem;
            border-radius: 4px;
            text-align: left;
        }

        .objective h3 {
            margin-bottom: 0.5rem;
            color: #2c3e50;
        }

        .objective p {
            margin-bottom: 0;
            font-size: 1rem;
        }

        .counter {
            position: fixed;
            bottom: 30px;
            left: 30px;
            color: #7f8c8d;
            font-size: 14px;
        }

        /* Ensemble specific styles */
        .ensemble-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 1rem;
            margin: 1.5rem 0;
        }

        .ensemble-item {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 4px;
            text-align: center;
            border: 2px solid #e9ecef;
        }

        .ensemble-item.header {
            background: #3498db;
            color: white;
            font-weight: bold;
        }

        .model-tree {
            stroke: #2c3e50;
            stroke-width: 2px;
            fill: none;
        }

        .model-node {
            fill: #3498db;
            stroke: #2980b9;
            stroke-width: 2px;
        }

        .boosting-arrow {
            stroke: #e74c3c;
            stroke-width: 3px;
            fill: none;
            marker-end: url(#arrowhead);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .slide {
                width: 95vw;
                height: 85vh;
                padding: 25px;
            }
            
            h1 { font-size: 2rem; }
            h2 { font-size: 1.6rem; }
            
            .grid-2, .grid-3, .objectives {
                grid-template-columns: 1fr;
                gap: 1.2rem;
            }
            
            .title-slide h1 {
                font-size: 2.2rem;
            }
        }
    </style>
</head>
<body>
    <div class="presentation">
        <!-- Slide 1: Title -->
        <div class="slide active title-slide" id="slide1">
            <h1>Boosting and Bagging</h1>
            <p class="subtitle">Ensemble Methods for Stronger Machine Learning</p>
            
            <div class="objectives">
                <div class="objective">
                    <h3>Ensemble Fundamentals</h3>
                    <p>Understand why combining models improves performance</p>
                </div>
                <div class="objective">
                    <h3>Bagging Methods</h3>
                    <p>Master bootstrap aggregating and random forests</p>
                </div>
                <div class="objective">
                    <h3>Boosting Algorithms</h3>
                    <p>Learn AdaBoost, gradient boosting, and XGBoost</p>
                </div>
                <div class="objective">
                    <h3>Practical Applications</h3>
                    <p>Apply ensemble methods to real-world problems</p>
                </div>
            </div>
        </div>

        <!-- Slide 2: Why Ensemble Methods Work -->
        <div class="slide" id="slide2">
            <h2>Why Ensemble Methods Work</h2>
            
            <div class="highlight">
                <p><strong>Ensemble methods combine multiple models to achieve better performance than any individual model, leveraging the wisdom of crowds principle to reduce errors and improve robustness.</strong></p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Bias-Variance Decomposition</h3>
                    <div class="formula">
                        $$\text{Error} = \text{Bias}^2 + \text{Variance} + \text{Noise}$$
                    </div>
                    <ul>
                        <li><strong>Bagging:</strong> Reduces variance by averaging</li>
                        <li><strong>Boosting:</strong> Reduces bias by sequential learning</li>
                        <li><strong>Stacking:</strong> Learns optimal combination weights</li>
                        <li><strong>Diversity:</strong> Key to ensemble success</li>
                    </ul>
                    
                    <div class="example">
                        <strong>Intuition:</strong> If models make different types of errors, averaging their predictions can cancel out individual mistakes.
                    </div>
                </div>
                <div>
                    <div class="viz" id="ensemble-overview-viz">
                        <div style="height: 100%; display: flex; align-items: center; justify-content: center; color: #95a5a6;">
                            Single Model vs Ensemble Performance
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 3: Bootstrap Aggregating (Bagging) -->
        <div class="slide" id="slide3">
            <h2>Bootstrap Aggregating (Bagging)</h2>
            
            <div class="grid-2">
                <div>
                    <h3>Algorithm Steps</h3>
                    <div class="highlight">
                        <h4>1. Bootstrap Sampling</h4>
                        <p>Create B bootstrap samples by sampling n examples with replacement from training set</p>
                    </div>
                    
                    <div class="highlight">
                        <h4>2. Train Base Models</h4>
                        <p>Train a model on each bootstrap sample independently</p>
                    </div>
                    
                    <div class="highlight">
                        <h4>3. Aggregate Predictions</h4>
                        <p>Average predictions (regression) or vote (classification)</p>
                    </div>
                </div>
                
                <div>
                    <h3>Mathematical Foundation</h3>
                    <div class="formula">
                        $$\hat{f}_{\text{bag}}(x) = \frac{1}{B}\sum_{b=1}^{B} \hat{f}_b(x)$$
                    </div>
                    <p>Where $\hat{f}_b$ is the model trained on bootstrap sample b.</p>
                    
                    <h3>Variance Reduction</h3>
                    <div class="formula">
                        $$\text{Var}(\bar{X}) = \frac{\sigma^2}{n}$$
                    </div>
                    <p>Averaging reduces variance by factor of n (if uncorrelated).</p>
                </div>
            </div>
            
            <div class="viz" id="bagging-process-viz">
                <div style="height: 200px; display: flex; align-items: center; justify-content: center; color: #95a5a6;">
                    Bagging Process Visualization
                </div>
            </div>
        </div>

        <!-- Slide 4: Random Forests -->
        <div class="slide" id="slide4">
            <h2>Random Forests: Bagging + Feature Randomness</h2>
            
            <div class="highlight">
                <p><strong>Random forests extend bagging by adding feature randomness, selecting a random subset of features at each split to decorrelate trees and improve generalization.</strong></p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Key Innovations</h3>
                    <ul>
                        <li><strong>Bootstrap Sampling:</strong> Each tree trained on different subset</li>
                        <li><strong>Feature Randomness:</strong> Random features at each split</li>
                        <li><strong>No Pruning:</strong> Trees grown deep to reduce bias</li>
                        <li><strong>Out-of-Bag Estimation:</strong> Internal validation</li>
                    </ul>
                    
                    <h3>Hyperparameters</h3>
                    <ul>
                        <li><strong>n_estimators:</strong> Number of trees (100-1000)</li>
                        <li><strong>max_features:</strong> Features per split (√p for classification)</li>
                        <li><strong>max_depth:</strong> Tree depth (None for full growth)</li>
                        <li><strong>min_samples_split:</strong> Minimum samples to split</li>
                    </ul>
                </div>
                
                <div>
                    <div class="viz" id="random-forest-viz">
                        <div style="height: 250px; display: flex; align-items: center; justify-content: center; color: #95a5a6;">
                            Random Forest Architecture
                        </div>
                    </div>
                    
                    <div class="example">
                        <strong>Out-of-Bag Error:</strong> Each example is "out-of-bag" for ~37% of trees, enabling unbiased error estimation without separate validation set.
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 5: AdaBoost -->
        <div class="slide" id="slide5">
            <h2>AdaBoost: Adaptive Boosting</h2>
            
            <div class="grid-2">
                <div>
                    <h3>Algorithm Steps</h3>
                    <div class="highlight">
                        <h4>1. Initialize Weights</h4>
                        <div class="formula">
                            $$w_i^{(1)} = \frac{1}{n}$$
                        </div>
                    </div>
                    
                    <div class="highlight">
                        <h4>2. Train Weak Learner</h4>
                        <p>Find classifier that minimizes weighted error</p>
                        <div class="formula">
                            $$\epsilon_t = \sum_{i: h_t(x_i) \neq y_i} w_i^{(t)}$$
                        </div>
                    </div>
                    
                    <div class="highlight">
                        <h4>3. Compute Classifier Weight</h4>
                        <div class="formula">
                            $$\alpha_t = \frac{1}{2}\ln\left(\frac{1-\epsilon_t}{\epsilon_t}\right)$$
                        </div>
                    </div>
                </div>
                
                <div>
                    <div class="highlight">
                        <h4>4. Update Example Weights</h4>
                        <div class="formula">
                            $$w_i^{(t+1)} = w_i^{(t)} \exp(-\alpha_t y_i h_t(x_i))$$
                        </div>
                        <p>Increase weights for misclassified examples</p>
                    </div>
                    
                    <div class="highlight">
                        <h4>5. Final Prediction</h4>
                        <div class="formula">
                            $$H(x) = \text{sign}\left(\sum_{t=1}^{T} \alpha_t h_t(x)\right)$$
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="example">
                <strong>Key Insight:</strong> AdaBoost focuses on hard examples by increasing their weights, forcing subsequent classifiers to pay more attention to previously misclassified cases.
            </div>
        </div>

        <!-- Slide 6: Gradient Boosting -->
        <div class="slide" id="slide6">
            <h2>Gradient Boosting Machines</h2>
            
            <div class="highlight">
                <p><strong>Gradient boosting fits models sequentially, with each new model trained to predict the residuals (errors) of the ensemble so far, using gradient descent in function space.</strong></p>
            </div>
            
            <div class="grid-2">
                <div>
                    <h3>Algorithm Framework</h3>
                    <div class="formula">
                        $$F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)$$
                    </div>
                    <p>Where $h_m$ is trained on negative gradients of loss function.</p>
                    
                    <h3>Gradient Computation</h3>
                    <div class="formula">
                        $$r_{im} = -\left[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right]_{F=F_{m-1}}$$
                    </div>
                    <p>Pseudo-residuals guide next model training.</p>
                </div>
                
                <div>
                    <h3>Loss Functions</h3>
                    <ul>
                        <li><strong>Squared Loss:</strong> $(y - F(x))^2$ for regression</li>
                        <li><strong>Absolute Loss:</strong> $|y - F(x)|$ for robust regression</li>
                        <li><strong>Logistic Loss:</strong> Cross-entropy for classification</li>
                        <li><strong>Quantile Loss:</strong> For quantile regression</li>
                    </ul>
                    
                    <div class="example">
                        <strong>Regularization:</strong>
                        <ul>
                            <li>Learning rate (shrinkage): 0.01-0.3</li>
                            <li>Tree depth: 3-8 levels</li>
                            <li>Subsampling: 0.5-0.8 fraction</li>
                            <li>Early stopping on validation</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 7: Modern Boosting: XGBoost -->
        <div class="slide" id="slide7">
            <h2>XGBoost: Extreme Gradient Boosting</h2>
            
            <div class="grid-2">
                <div>
                    <h3>Key Innovations</h3>
                    <ul>
                        <li><strong>Regularized Objective:</strong> L1 and L2 penalties on leaf weights</li>
                        <li><strong>Second-Order Gradients:</strong> Newton's method approximation</li>
                        <li><strong>Parallel Processing:</strong> Parallelized tree construction</li>
                        <li><strong>Missing Value Handling:</strong> Learns optimal direction</li>
                        <li><strong>Built-in Cross-Validation:</strong> Automatic early stopping</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Objective Function</h3>
                    <div class="formula">
                        $$\mathcal{L}^{(t)} = \sum_{i=1}^{n} l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) + \Omega(f_t)$$
                    </div>
                    
                    <h3>Regularization Term</h3>
                    <div class="formula">
                        $$\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^{T} w_j^2$$
                    </div>
                    <p>Where T is number of leaves, $w_j$ are leaf weights.</p>
                </div>
            </div>
            
            <div class="ensemble-comparison">
                <div class="ensemble-item header">Framework</div>
                <div class="ensemble-item header">Strengths</div>
                <div class="ensemble-item header">Use Cases</div>
                
                <div class="ensemble-item"><strong>XGBoost</strong></div>
                <div class="ensemble-item">High performance, feature importance</div>
                <div class="ensemble-item">Tabular data, competitions</div>
                
                <div class="ensemble-item"><strong>LightGBM</strong></div>
                <div class="ensemble-item">Memory efficient, fast training</div>
                <div class="ensemble-item">Large datasets, real-time</div>
                
                <div class="ensemble-item"><strong>CatBoost</strong></div>
                <div class="ensemble-item">Categorical features, no preprocessing</div>
                <div class="ensemble-item">Mixed data types, minimal tuning</div>
            </div>
        </div>

        <!-- Slide 8: Bagging vs Boosting -->
        <div class="slide" id="slide8">
            <h2>Bagging vs Boosting: Key Differences</h2>
            
            <div class="ensemble-comparison">
                <div class="ensemble-item header">Aspect</div>
                <div class="ensemble-item header">Bagging</div>
                <div class="ensemble-item header">Boosting</div>
                
                <div class="ensemble-item"><strong>Training</strong></div>
                <div class="ensemble-item">Parallel (independent)</div>
                <div class="ensemble-item">Sequential (dependent)</div>
                
                <div class="ensemble-item"><strong>Focus</strong></div>
                <div class="ensemble-item">Reduce variance</div>
                <div class="ensemble-item">Reduce bias</div>
                
                <div class="ensemble-item"><strong>Base Models</strong></div>
                <div class="ensemble-item">Strong learners (deep trees)</div>
                <div class="ensemble-item">Weak learners (stumps)</div>
                
                <div class="ensemble-item"><strong>Overfitting</strong></div>
                <div class="ensemble-item">Less prone to overfit</div>
                <div class="ensemble-item">Can overfit with noise</div>
                
                <div class="ensemble-item"><strong>Computational</strong></div>
                <div class="ensemble-item">Easily parallelizable</div>
                <div class="ensemble-item">Inherently sequential</div>
                
                <div class="ensemble-item"><strong>Robustness</strong></div>
                <div class="ensemble-item">Robust to outliers</div>
                <div class="ensemble-item">Sensitive to outliers</div>
            </div>
            
            <div class="viz" id="bagging-vs-boosting-viz">
                <div style="height: 200px; display: flex; align-items: center; justify-content: center; color: #95a5a6;">
                    Bagging vs Boosting Learning Curves
                </div>
            </div>
        </div>

        <!-- Slide 9: Advanced Ensemble Techniques -->
        <div class="slide" id="slide9">
            <h2>Advanced Ensemble Techniques</h2>
            
            <div class="grid-2">
                <div>
                    <h3>Stacking (Stacked Generalization)</h3>
                    <ul>
                        <li><strong>Level 0:</strong> Base models trained on data</li>
                        <li><strong>Level 1:</strong> Meta-learner combines base predictions</li>
                        <li><strong>Cross-validation:</strong> Prevents overfitting to base models</li>
                        <li><strong>Diversity:</strong> Use different algorithm types</li>
                    </ul>
                    
                    <h3>Blending</h3>
                    <ul>
                        <li>Holdout set for meta-learner training</li>
                        <li>Simpler than full stacking</li>
                        <li>Less prone to overfitting</li>
                        <li>Popular in competitions</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Ensemble Diversity</h3>
                    <ul>
                        <li><strong>Algorithm Diversity:</strong> Different model types</li>
                        <li><strong>Data Diversity:</strong> Different features/samples</li>
                        <li><strong>Parameter Diversity:</strong> Different hyperparameters</li>
                        <li><strong>Training Diversity:</strong> Different training procedures</li>
                    </ul>
                    
                    <div class="example">
                        <strong>Best Practices:</strong>
                        <ul>
                            <li>Combine uncorrelated models</li>
                            <li>Balance individual accuracy with diversity</li>
                            <li>Use cross-validation for model selection</li>
                            <li>Monitor ensemble complexity</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div class="highlight">
                <p><strong>Ensemble Success Formula:</strong> High individual accuracy + Low correlation between models = Strong ensemble performance</p>
            </div>
        </div>

        <!-- Slide 10: Practical Guidelines -->
        <div class="slide" id="slide10">
            <h2>Implementation Guidelines and Best Practices</h2>
            
            <div class="grid-2">
                <div>
                    <h3>When to Use Each Method</h3>
                    <ul>
                        <li><strong>Random Forests:</strong> General-purpose, interpretable, robust baseline</li>
                        <li><strong>Gradient Boosting:</strong> High accuracy needed, careful tuning possible</li>
                        <li><strong>XGBoost/LightGBM:</strong> Tabular data competitions, feature importance</li>
                        <li><strong>Bagging:</strong> High-variance models, parallel processing available</li>
                    </ul>
                    
                    <h3>Common Pitfalls</h3>
                    <ul>
                        <li>Overfitting with too many boosting rounds</li>
                        <li>Using correlated base models</li>
                        <li>Ignoring computational constraints</li>
                        <li>Not validating ensemble diversity</li>
                    </ul>
                </div>
                
                <div>
                    <h3>Hyperparameter Tuning</h3>
                    <ul>
                        <li><strong>Random Forest:</strong> n_estimators, max_features, max_depth</li>
                        <li><strong>XGBoost:</strong> learning_rate, max_depth, subsample, reg_alpha/lambda</li>
                        <li><strong>Early Stopping:</strong> Use validation set to prevent overfitting</li>
                        <li><strong>Cross-Validation:</strong> K-fold for robust performance estimates</li>
                    </ul>
                    
                    <div class="example">
                        <strong>Performance Tips:</strong>
                        <ul>
                            <li>Start with Random Forest baseline</li>
                            <li>Use learning curves for boosting</li>
                            <li>Monitor training vs validation error</li>
                            <li>Consider ensemble of ensembles</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div class="highlight">
                <p><strong>Key Takeaway:</strong> Ensemble methods consistently achieve state-of-the-art performance on tabular data. They're often the first choice for machine learning competitions and real-world applications where predictive accuracy is paramount.</p>
            </div>
        </div>
    </div>

    <!-- Navigation -->
    <div class="counter">
        <span id="current">1</span> / <span id="total">10</span>
    </div>

    <script>
        let currentSlide = 1;
        const totalSlides = 10;

        function showSlide(n) {
            const slides = document.querySelectorAll('.slide');
            if (n > totalSlides) currentSlide = 1;
            if (n < 1) currentSlide = totalSlides;
            
            slides.forEach(slide => slide.classList.remove('active'));
            slides[currentSlide - 1].classList.add('active');
            
            document.getElementById('current').textContent = currentSlide;
            
            // Initialize visualizations
            setTimeout(() => initViz(currentSlide), 100);
        }

        function nextSlide() {
            if (currentSlide < totalSlides) {
                currentSlide++;
                showSlide(currentSlide);
            }
        }

        function previousSlide() {
            if (currentSlide > 1) {
                currentSlide--;
                showSlide(currentSlide);
            }
        }

        // Keyboard navigation
        document.addEventListener('keydown', function(e) {
            if (e.key === 'ArrowRight' || e.key === ' ') nextSlide();
            if (e.key === 'ArrowLeft') previousSlide();
        });

        // Visualization functions
        function initViz(slideNum) {
            console.log('Initializing visualization for slide:', slideNum);
            
            try {
                switch(slideNum) {
                    case 2:
                        createEnsembleOverviewViz();
                        break;
                    case 3:
                        createBaggingProcessViz();
                        break;
                    case 4:
                        createRandomForestViz();
                        break;
                    case 8:
                        createBaggingVsBoostingViz();
                        break;
                }
            } catch (error) {
                console.error('Visualization error:', error);
            }
        }

        function createEnsembleOverviewViz() {
            const container = d3.select('#ensemble-overview-viz');
            container.selectAll('*').remove();
            
            const width = 400;
            const height = 250;
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            
            const svg = container
                .append('svg')
                .attr('width', width)
                .attr('height', height);
            
            // Generate performance data
            const epochs = d3.range(1, 21);
            const singleModel = epochs.map(e => 0.85 - 0.1 * Math.exp(-e/5) + 0.02 * Math.random());
            const ensemble = epochs.map(e => 0.92 - 0.05 * Math.exp(-e/8) + 0.01 * Math.random());
            
            const xScale = d3.scaleLinear()
                .domain([1, 20])
                .range([margin.left, width - margin.right]);
            
            const yScale = d3.scaleLinear()
                .domain([0.7, 1.0])
                .range([height - margin.bottom, margin.top]);
            
            const line = d3.line()
                .x((d, i) => xScale(epochs[i]))
                .y(d => yScale(d));
            
            // Draw performance curves
            svg.append('path')
                .datum(singleModel)
                .attr('d', line)
                .attr('stroke', '#e74c3c')
                .attr('stroke-width', 3)
                .attr('fill', 'none');
            
            svg.append('path')
                .datum(ensemble)
                .attr('d', line)
                .attr('stroke', '#2ecc71')
                .attr('stroke-width', 3)
                .attr('fill', 'none');
            
            // Add legend
            svg.append('text')
                .attr('x', width - 120)
                .attr('y', 40)
                .text('Single Model')
                .attr('fill', '#e74c3c')
                .attr('font-size', '12px');
            
            svg.append('text')
                .attr('x', width - 120)
                .attr('y', 55)
                .text('Ensemble')
                .attr('fill', '#2ecc71')
                .attr('font-size', '12px');
            
            // Add axes labels
            svg.append('text')
                .attr('x', width/2)
                .attr('y', height - 5)
                .text('Training Progress')
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px');
            
            svg.append('text')
                .attr('x', 15)
                .attr('y', height/2)
                .text('Accuracy')
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px')
                .attr('transform', `rotate(-90, 15, ${height/2})`);
        }

        function createBaggingProcessViz() {
            const container = d3.select('#bagging-process-viz');
            container.selectAll('*').remove();
            
            const width = 500;
            const height = 150;
            
            const svg = container
                .append('svg')
                .attr('width', width)
                .attr('height', height);
            
            // Draw the bagging process
            const stages = [
                {name: 'Original\nDataset', x: 60, width: 80},
                {name: 'Bootstrap\nSamples', x: 180, width: 60},
                {name: 'Base\nModels', x: 280, width: 50},
                {name: 'Final\nPrediction', x: 400, width: 80}
            ];
            
            stages.forEach((stage, i) => {
                // Draw stage box
                svg.append('rect')
                    .attr('x', stage.x - stage.width/2)
                    .attr('y', 50)
                    .attr('width', stage.width)
                    .attr('height', 60)
                    .attr('fill', '#f8f9fa')
                    .attr('stroke', '#3498db')
                    .attr('stroke-width', 2)
                    .attr('rx', 5);
                
                // Add stage label
                svg.append('text')
                    .attr('x', stage.x)
                    .attr('y', 85)
                    .text(stage.name)
                    .attr('text-anchor', 'middle')
                    .attr('font-size', '11px')
                    .attr('fill', '#2c3e50');
                
                // Add arrows between stages
                if (i < stages.length - 1) {
                    const nextStage = stages[i + 1];
                    svg.append('line')
                        .attr('x1', stage.x + stage.width/2)
                        .attr('y1', 80)
                        .attr('x2', nextStage.x - nextStage.width/2)
                        .attr('y2', 80)
                        .attr('stroke', '#7f8c8d')
                        .attr('stroke-width', 2)
                        .attr('marker-end', 'url(#arrow)');
                }
            });
            
            // Add multiple bootstrap samples visualization
            for (let i = 0; i < 3; i++) {
                svg.append('rect')
                    .attr('x', 150)
                    .attr('y', 30 + i * 25)
                    .attr('width', 40)
                    .attr('height', 15)
                    .attr('fill', '#ecf0f1')
                    .attr('stroke', '#bdc3c7')
                    .attr('rx', 2);
            }
            
            // Add multiple models visualization
            for (let i = 0; i < 3; i++) {
                svg.append('circle')
                    .attr('cx', 280)
                    .attr('cy', 40 + i * 25)
                    .attr('r', 8)
                    .attr('fill', '#3498db')
                    .attr('opacity', 0.7);
                
                svg.append('text')
                    .attr('x', 280)
                    .attr('y', 44 + i * 25)
                    .text(`M${i+1}`)
                    .attr('text-anchor', 'middle')
                    .attr('font-size', '8px')
                    .attr('fill', 'white');
            }
            
            // Arrow marker
            svg.append('defs')
                .append('marker')
                .attr('id', 'arrow')
                .attr('markerWidth', 10)
                .attr('markerHeight', 7)
                .attr('refX', 9)
                .attr('refY', 3.5)
                .attr('orient', 'auto')
                .append('polygon')
                .attr('points', '0 0, 10 3.5, 0 7')
                .attr('fill', '#7f8c8d');
        }

        function createRandomForestViz() {
            const container = d3.select('#random-forest-viz');
            container.selectAll('*').remove();
            
            const width = 400;
            const height = 200;
            
            const svg = container
                .append('svg')
                .attr('width', width)
                .attr('height', height);
            
            // Draw multiple decision trees
            const treePositions = [
                {x: 80, y: 100},
                {x: 160, y: 100},
                {x: 240, y: 100},
                {x: 320, y: 100}
            ];
            
            treePositions.forEach((pos, i) => {
                // Tree trunk
                svg.append('line')
                    .attr('x1', pos.x)
                    .attr('y1', pos.y)
                    .attr('x2', pos.x)
                    .attr('y2', pos.y - 40)
                    .attr('stroke', '#8b4513')
                    .attr('stroke-width', 4);
                
                // Tree branches
                svg.append('line')
                    .attr('x1', pos.x)
                    .attr('y1', pos.y - 40)
                    .attr('x2', pos.x - 15)
                    .attr('y2', pos.y - 60)
                    .attr('stroke', '#8b4513')
                    .attr('stroke-width', 2);
                
                svg.append('line')
                    .attr('x1', pos.x)
                    .attr('y1', pos.y - 40)
                    .attr('x2', pos.x + 15)
                    .attr('y2', pos.y - 60)
                    .attr('stroke', '#8b4513')
                    .attr('stroke-width', 2);
                
                // Tree leaves
                svg.append('circle')
                    .attr('cx', pos.x - 15)
                    .attr('cy', pos.y - 60)
                    .attr('r', 8)
                    .attr('fill', '#2ecc71')
                    .attr('opacity', 0.8);
                
                svg.append('circle')
                    .attr('cx', pos.x + 15)
                    .attr('cy', pos.y - 60)
                    .attr('r', 8)
                    .attr('fill', '#2ecc71')
                    .attr('opacity', 0.8);
                
                // Tree label
                svg.append('text')
                    .attr('x', pos.x)
                    .attr('y', pos.y + 20)
                    .text(`Tree ${i+1}`)
                    .attr('text-anchor', 'middle')
                    .attr('font-size', '10px');
            });
            
            // Add voting arrow
            svg.append('path')
                .attr('d', 'M 350 100 Q 380 80 380 50')
                .attr('stroke', '#e74c3c')
                .attr('stroke-width', 3)
                .attr('fill', 'none')
                .attr('marker-end', 'url(#arrow)');
            
            // Add final prediction
            svg.append('text')
                .attr('x', 380)
                .attr('y', 35)
                .text('Vote')
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px')
                .attr('font-weight', 'bold')
                .attr('fill', '#e74c3c');
            
            // Add forest label
            svg.append('text')
                .attr('x', 200)
                .attr('y', 180)
                .text('Random Forest: Bootstrap + Feature Randomness')
                .attr('text-anchor', 'middle')
                .attr('font-size', '14px')
                .attr('font-weight', 'bold')
                .attr('fill', '#2c3e50');
        }

        function createBaggingVsBoostingViz() {
            const container = d3.select('#bagging-vs-boosting-viz');
            container.selectAll('*').remove();
            
            const width = 500;
            const height = 150;
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            
            const svg = container
                .append('svg')
                .attr('width', width)
                .attr('height', height);
            
            // Generate learning curves
            const iterations = d3.range(1, 21);
            const baggingError = iterations.map(i => 0.25 * Math.exp(-i/8) + 0.05 + 0.01 * Math.random());
            const boostingError = iterations.map(i => 0.4 * Math.exp(-i/4) + 0.02 + 0.005 * Math.random());
            
            const xScale = d3.scaleLinear()
                .domain([1, 20])
                .range([margin.left, width - margin.right]);
            
            const yScale = d3.scaleLinear()
                .domain([0, 0.35])
                .range([height - margin.bottom, margin.top]);
            
            const line = d3.line()
                .x((d, i) => xScale(iterations[i]))
                .y(d => yScale(d));
            
            // Draw error curves
            svg.append('path')
                .datum(baggingError)
                .attr('d', line)
                .attr('stroke', '#3498db')
                .attr('stroke-width', 3)
                .attr('fill', 'none');
            
            svg.append('path')
                .datum(boostingError)
                .attr('d', line)
                .attr('stroke', '#e74c3c')
                .attr('stroke-width', 3)
                .attr('fill', 'none');
            
            // Add legend
            svg.append('text')
                .attr('x', width - 100)
                .attr('y', 40)
                .text('Bagging')
                .attr('fill', '#3498db')
                .attr('font-size', '12px');
            
            svg.append('text')
                .attr('x', width - 100)
                .attr('y', 55)
                .text('Boosting')
                .attr('fill', '#e74c3c')
                .attr('font-size', '12px');
            
            // Add axes labels
            svg.append('text')
                .attr('x', width/2)
                .attr('y', height - 5)
                .text('Number of Models')
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px');
            
            svg.append('text')
                .attr('x', 15)
                .attr('y', height/2)
                .text('Error Rate')
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px')
                .attr('transform', `rotate(-90, 15, ${height/2})`);
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            console.log('DOM loaded, initializing...');
            showSlide(1);
        });
    </script>
</body>
</html>
